{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing generalization to eval dataset (transform_coltrane_2021_07_28_1.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "# Send logging outputs to stdout (comment this out if preferred)\n",
    "# logger = logging.getLogger()\n",
    "# logger.setLevel(logging.INFO)\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Change this to egl or glfw if available\n",
    "os.environ[\"MUJOCO_GL\"] = \"glfw\"\n",
    "\n",
    "from track_mjx.agent import checkpointing\n",
    "from track_mjx.analysis import rollout, render, utils\n",
    "from track_mjx.environment import wrappers\n",
    "from typing import Dict, Callable\n",
    "import numpy as np\n",
    "import jax\n",
    "from brax.envs.base import Env\n",
    "from track_mjx.environment.walker.rodent import Rodent\n",
    "from track_mjx.environment.walker.fly import Fly\n",
    "from brax import envs\n",
    "from typing import Dict, Callable\n",
    "import hydra\n",
    "import logging\n",
    "from track_mjx.environment.task.reward import RewardConfig\n",
    "from jax import numpy as jnp\n",
    "\n",
    "from track_mjx.environment.task.multi_clip_tracking import MultiClipTracking\n",
    "from track_mjx.environment.task.single_clip_tracking import SingleClipTracking\n",
    "from track_mjx.environment import wrappers\n",
    "from track_mjx.io import load\n",
    "\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "from pathlib import Path\n",
    "\n",
    "# don't preallocate jax memory\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_path = \"/Users/charleszhang/GitHub/stac-mjx/transform_coltrane_2021_07_28_1.h5\"\n",
    "\n",
    "# replace with your checkpoint path\n",
    "ckpt_path = \"/Users/charleszhang/GitHub/track-mjx/model_checkpoints/ademamix_64\"  \n",
    "# Load config from checkpoint \n",
    "ckpt = checkpointing.load_checkpoint_for_eval(ckpt_path)\n",
    "\n",
    "cfg = ckpt[\"cfg\"]\n",
    "\n",
    "# make some changes to the config\n",
    "# replace with absolute path to your data\n",
    "# -- your notebook may not have access to the same relative path\n",
    "cfg.data_path = \"/Users/charleszhang/GitHub/track-mjx/data/transform_snips.h5\"\n",
    "cfg.train_setup.checkpoint_to_restore = ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames_per_clip=1000\n",
    "inference_fn = checkpointing.load_inference_fn(cfg, ckpt[\"policy\"], get_activation=False)\n",
    "reference_clip = load.make_multiclip_data(eval_data_path, n_frames_per_clip=n_frames_per_clip)\n",
    "reference_clip.position.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create env with test set reference clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.register_environment(\"rodent_multi_clip\", MultiClipTracking)\n",
    "\n",
    "env_args = cfg[\"env_config\"][\"env_args\"]\n",
    "env_rewards = cfg[\"env_config\"][\"reward_weights\"]\n",
    "walker_config = cfg[\"walker_config\"]\n",
    "traj_config = cfg[\"reference_config\"]\n",
    "\n",
    "walker = Rodent(**walker_config)\n",
    "\n",
    "reward_config = RewardConfig(**env_rewards)\n",
    "# Automatically match dict keys and func needs\n",
    "env = envs.get_environment(\n",
    "    env_name=\"rodent_multi_clip\",\n",
    "    reference_clip=reference_clip,\n",
    "    walker=walker,\n",
    "    reward_config=reward_config,\n",
    "    **env_args,\n",
    "    **traj_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_env = wrappers.RenderRolloutWrapperMulticlipTracking(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vmap wrapper and auto align wrapper\n",
    "align_vmap_env = wrappers.AutoAlignWrapperTracking(\n",
    "        wrappers.RenderRolloutVmapWrapper(rollout_env)\n",
    "    )\n",
    "align_reset = align_vmap_env.reset \n",
    "align_step = align_vmap_env.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JIT-compile the necessary functions\n",
    "jit_inference_fn = jax.jit(jax.vmap(inference_fn))\n",
    "jit_align_reset = jax.jit(align_reset)\n",
    "jit_align_step = jax.jit(align_step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform data to multiclip, then initialize to multiclip with a long clip length (5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoalign wrapper rollout\n",
    "num_envs = 3\n",
    "key_envs = jax.random.split(jax.random.PRNGKey(0), num_envs)\n",
    "\n",
    "clip_idxs = jnp.arange(0, num_envs)\n",
    "\n",
    "init_states = jit_align_reset(key_envs, clip_idx=clip_idxs)\n",
    "num_steps = (\n",
    "    int(n_frames_per_clip * env._steps_for_cur_frame) - 1\n",
    ") \n",
    "\n",
    "rollouts = [init_states]\n",
    "state = init_states\n",
    "activations = []\n",
    "rng_policy = jax.random.split(jax.random.PRNGKey(1), num_envs)\n",
    "\n",
    "for i in tqdm(range(num_steps)):\n",
    "    _, rng_policy = jax.vmap(jax.random.split)(rng_policy)\n",
    "    ctrl, extras = jit_inference_fn(state.obs, rng_policy)\n",
    "    # activations.append(extras[\"activations\"])\n",
    "    state = jit_align_step(state, ctrl)\n",
    "    rollouts.append(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render rollouts\n",
    "rollout_dict = {\n",
    "    \"qposes_ref\": [r.pipeline_state.qpos[0] for r in rollouts], # set this as the mocap qpos\n",
    "    \"qposes_rollout\": [r.pipeline_state.qpos[0] for r in rollouts]\n",
    "}\n",
    "frames, realtime_framerate = render.render_rollout(cfg, rollout_dict)\n",
    "render.display_video(frames, framerate=realtime_framerate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of done frames per hour\n",
    "dones = jnp.array([r.metrics[\"done\"] for r in rollouts])\n",
    "done_count = dones.sum()\n",
    "done_per_hour = done_count * (3600 / (dones.size / realtime_framerate))  # Scale up to per hour\n",
    "done_per_hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot reward over time for a 2000 (40 second) continuous rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot([r.reward[0] for r in rollouts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
