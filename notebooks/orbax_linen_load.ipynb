{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import orbax.checkpoint as ocp\n",
    "\n",
    "\n",
    "from track_mjx.agent.custom_ppo import TrainingState\n",
    "from track_mjx.agent import custom_losses as ppo_losses\n",
    "from track_mjx.agent import custom_ppo, custom_ppo_networks\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import optax\n",
    "from brax import envs\n",
    "from brax.training.acme import running_statistics, specs\n",
    "from track_mjx.environment import custom_wrappers\n",
    "from track_mjx.environment.task.multi_clip_tracking import RodentMultiClipTracking\n",
    "from track_mjx.environment.task.single_clip_tracking import RodentTracking\n",
    "from track_mjx.environment.walker.rodent import Rodent\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from omegaconf import OmegaConf\n",
    "import pickle\n",
    "import functools\n",
    "\n",
    "if GlobalHydra.instance().is_initialized():\n",
    "    GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=\"./../track_mjx/config\")\n",
    "\n",
    "# Load the config file\n",
    "cfg = compose(config_name=\"rodent-mc-intention\")\n",
    "\n",
    "\n",
    "envs.register_environment(\"single clip\", RodentTracking)\n",
    "envs.register_environment(\"multi clip\", RodentMultiClipTracking)\n",
    "\n",
    "# config files\n",
    "env_cfg = hydra.compose(config_name=\"rodent-mc-intention\")\n",
    "env_args = cfg.env_config[\"env_args\"]\n",
    "env_rewards = cfg.env_config[\"reward_weights\"]\n",
    "train_config = cfg.train_setup[\"train_config\"]\n",
    "wlaker_config = cfg[\"walker_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Kevin): add this as a yaml config\n",
    "walker = Rodent(**wlaker_config)\n",
    "\n",
    "# TODO(Scott): move this to track_mjx.io module\n",
    "input_data_path = hydra.utils.to_absolute_path(\"../data/twoClips.p\")\n",
    "print(f\"Loading data: {input_data_path}\")\n",
    "with open(input_data_path, \"rb\") as file:\n",
    "    reference_clip = pickle.load(file)\n",
    "\n",
    "# Automatically match dict keys and func needs\n",
    "environment = envs.get_environment(\n",
    "    env_name=cfg.env_config.env_name,\n",
    "    reference_clip=reference_clip,\n",
    "    walker=walker,\n",
    "    **env_args,\n",
    "    **env_rewards,\n",
    ")\n",
    "\n",
    "# Episode length is equal to (clip length - random init range - traj length) * steps per cur frame.\n",
    "# Will work on not hardcoding these values later\n",
    "episode_length = (250 - 50 - 5) * environment._steps_for_cur_frame\n",
    "print(f\"episode_length {episode_length}\")\n",
    "\n",
    "\n",
    "# put your model path here\n",
    "model_path = \"/root/vast/scott-yang/track-mjx/model_checkpoints/930248f3-2319-4028-b77a-5d503cb58f6b\"\n",
    "\n",
    "# initialize orbax checkpoint manager\n",
    "# TODO (Scott): add the checkpoint parameter to config file.\n",
    "mgr_options = ocp.CheckpointManagerOptions(create=True, max_to_keep=3, keep_period=2, step_prefix=\"PPONetwork\")\n",
    "ckpt_mgr = ocp.CheckpointManager(model_path, ocp.Checkpointer(ocp.PyTreeCheckpointHandler()), mgr_options)\n",
    "\n",
    "train_fn = functools.partial(\n",
    "    custom_ppo.train,\n",
    "    **train_config,\n",
    "    num_evals=int(cfg.train_setup.train_config.num_timesteps / cfg.train_setup.eval_every),\n",
    "    episode_length=episode_length,\n",
    "    kl_weight=cfg.network_config.kl_weight,\n",
    "    network_factory=functools.partial(\n",
    "        custom_ppo_networks.make_intention_ppo_networks,\n",
    "        encoder_hidden_layer_sizes=tuple(cfg.network_config.encoder_layer_sizes),\n",
    "        decoder_hidden_layer_sizes=tuple(cfg.network_config.decoder_layer_sizes),\n",
    "        value_hidden_layer_sizes=tuple(cfg.network_config.critic_layer_sizes),\n",
    "    ),\n",
    "    ckpt_mgr=ckpt_mgr,\n",
    ")\n",
    "\n",
    "network_factory = functools.partial(\n",
    "    custom_ppo_networks.make_intention_ppo_networks,\n",
    "    encoder_hidden_layer_sizes=tuple(cfg.network_config.encoder_layer_sizes),\n",
    "    decoder_hidden_layer_sizes=tuple(cfg.network_config.decoder_layer_sizes),\n",
    "    value_hidden_layer_sizes=tuple(cfg.network_config.critic_layer_sizes),\n",
    ")\n",
    "\n",
    "\n",
    "seed = 42\n",
    "\n",
    "key = jax.random.PRNGKey(seed)\n",
    "global_key, local_key = jax.random.split(key)\n",
    "local_key, key_env, eval_key = jax.random.split(local_key, 3)\n",
    "# key_networks should be global, so that networks are initialized the same\n",
    "# way for different processes.\n",
    "key_policy, key_value, policy_params_fn_key = jax.random.split(global_key, 3)\n",
    "\n",
    "\n",
    "v_randomization_fn = None\n",
    "\n",
    "if isinstance(environment, envs.Env):\n",
    "    wrap_for_training = custom_wrappers.wrap\n",
    "else:\n",
    "    wrap_for_training = custom_wrappers.wrap\n",
    "\n",
    "env = wrap_for_training(\n",
    "    environment,\n",
    "    episode_length=episode_length,\n",
    "    action_repeat=1,\n",
    "    randomization_fn=v_randomization_fn,\n",
    ")\n",
    "\n",
    "reset_fn = env.reset\n",
    "key_envs = jax.random.split(key_env, 1)\n",
    "env_state = reset_fn(key_envs)\n",
    "\n",
    "normalize = lambda x, y: x\n",
    "if True:\n",
    "    normalize = running_statistics.normalize\n",
    "ppo_network = network_factory(\n",
    "    env_state.obs.shape[-1],\n",
    "    int(env_state.info[\"reference_obs_size\"][0]),\n",
    "    env.action_size,\n",
    "    preprocess_observations_fn=normalize,\n",
    ")\n",
    "make_policy = custom_ppo_networks.make_inference_fn(ppo_network)\n",
    "\n",
    "optimizer = optax.adam(learning_rate=1e-4)\n",
    "\n",
    "init_params = ppo_losses.PPONetworkParams(\n",
    "    policy=ppo_network.policy_network.init(key_policy),\n",
    "    value=ppo_network.value_network.init(key_value),\n",
    ")\n",
    "\n",
    "training_state = TrainingState(  # pytype: disable=wrong-arg-types  # jax-ndarray\n",
    "    optimizer_state=optimizer.init(init_params),  # pytype: disable=wrong-arg-types  # numpy-scalars\n",
    "    params=init_params,\n",
    "    normalizer_params=running_statistics.init_state(specs.Array(env_state.obs.shape[-1:], jnp.dtype(\"float32\"))),\n",
    "    env_steps=0,\n",
    ")\n",
    "\n",
    "abstract_policy = (training_state.normalizer_params, training_state.params.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the whole model (both policy module, and training state)\n",
    "\n",
    "options = ocp.CheckpointManagerOptions(step_prefix=\"PPONetwork\")\n",
    "with ocp.CheckpointManager(\n",
    "    \"/root/vast/scott-yang/track-mjx/model_checkpoints/930248f3-2319-4028-b77a-5d503cb58f6b\",\n",
    "    options=options,\n",
    ") as mngr:\n",
    "    cp = mngr.restore(0, args=ocp.args.Composite(policy=ocp.args.StandardRestore(abstract_policy)))\n",
    "    ts = mngr.restore(0, args=ocp.args.Composite(train_state=ocp.args.StandardRestore(training_state)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following is how we save multiple items -- with the new `ocp` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ocp.CheckpointManagerOptions()\n",
    "mngr = ocp.CheckpointManager(\n",
    "    ocp.test_utils.erase_and_create_empty(\"/root/vast/scott-yang/track-mjx/notebooks/test/ckpt4\"),\n",
    "    # `item_names` defines an up-front contract about what items the\n",
    "    # CheckpointManager will be dealing with.\n",
    "    options=options,\n",
    ")\n",
    "pytree = {\"A\": 1}\n",
    "extra_metadata = {\"B\": 2}\n",
    "mngr.save(\n",
    "    0, args=ocp.args.Composite(state=ocp.args.StandardSave(pytree), extra_metadata=ocp.args.JsonSave(extra_metadata))\n",
    ")\n",
    "mngr.wait_until_finished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ocp.CheckpointManagerOptions()\n",
    "mngr = ocp.CheckpointManager(\n",
    "    ocp.test_utils.erase_and_create_empty(\"/root/vast/scott-yang/track-mjx/notebooks/test/ckpt3\"),\n",
    "    {\n",
    "        \"state\": ocp.Checkpointer(ocp.PyTreeCheckpointHandler()),\n",
    "        \"extra_metadata\": ocp.Checkpointer(ocp.JsonCheckpointHandler()),\n",
    "    },\n",
    "    options=options,\n",
    ")\n",
    "\n",
    "restore_args = ocp.checkpoint_utils.construct_restore_args(pytree)\n",
    "mngr.save(0, {\"state\": pytree, \"extra_metadata\": extra_metadata})\n",
    "mngr.wait_until_finished()\n",
    "\n",
    "mngr.restore(\n",
    "    0,\n",
    "    items={\"state\": pytree, \"extra_metadata\": None},\n",
    "    restore_kwargs={\"state\": {\"restore_args\": restore_args}, \"extra_metadata\": None},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ocp.CheckpointManagerOptions()\n",
    "mngr = ocp.CheckpointManager(\n",
    "    \"/root/vast/scott-yang/track-mjx/notebooks/test/ckpt4\",\n",
    "    # `item_names` defines an up-front contract about what items the\n",
    "    # CheckpointManager will be dealing with.\n",
    "    options=options,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "It is possible to only load partially of the checkpoint, but I need to create the abstract pytree using the previous methods, which should not be that hard.\n",
    "\n",
    "The following cell demonstrates how to load only the state, but not the extra metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_pytree = {\"A\": 1}\n",
    "mngr.restore(0, args=ocp.args.Composite(state=ocp.args.StandardRestore(abstract_pytree)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track_mjx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
