{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and render a rollout for existing checkpoint\n",
    "\n",
    "This notebook demonstrates how to load a training checkpoint, perform a rollout, and render the result. Full network activations are saved as an output of this rollout for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "# Change this to egl or glfw if available\n",
    "os.environ[\"MUJOCO_GL\"] = \"osmesa\"\n",
    "import mediapy as media\n",
    "\n",
    "from track_mjx.agent import checkpointing\n",
    "from track_mjx.analysis import rollout, render, utils\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n",
      "WARNING:absl:Provided metadata contains unknown key custom. Adding it to custom_metadata.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /n/holylabs-olveczky/Users/charleszhang/track-mjx/model_checkpoints/scott_best at step 99\n"
     ]
    }
   ],
   "source": [
    "# replace with your checkpoint path\n",
    "ckpt_path = Path.cwd().parent / \"model_checkpoints/scott_best\"\n",
    "# Load config from checkpoint \n",
    "ckpt = checkpointing.load_checkpoint_for_eval(ckpt_path)\n",
    "\n",
    "cfg = ckpt[\"cfg\"]\n",
    "\n",
    "# make some changes to the config\n",
    "# replace with absolute path to your data\n",
    "# -- your notebook may not have access to the same relative path\n",
    "# cfg.data_path = Path.cwd().parent / \"data/transform_snips.h5\"\n",
    "# cfg.data_path = Path.cwd().parent / \"data/transform_coltrane_2021_07_29_1.h5\"\n",
    "# cfg.train_setup.checkpoint_to_restore = ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vnl_mjx.tasks.rodent import imitation\n",
    "\n",
    "def _track_to_vnl_cfg(cfg):\n",
    "    \"\"\"Replace the config values with the ones in our hydra cfg\"\"\"\n",
    "    env_cfg = imitation.default_config()\n",
    "\n",
    "    # Map environment parameters directly\n",
    "    env_args = cfg.env_config.env_args\n",
    "    env_cfg.solver = env_args.solver\n",
    "    env_cfg.iterations = env_args.iterations\n",
    "    env_cfg.ls_iterations = env_args.ls_iterations\n",
    "    env_cfg.sim_dt = env_args.mj_model_timestep\n",
    "    env_cfg.mocap_hz = env_args.mocap_hz\n",
    "\n",
    "    # Map walker parameters directly\n",
    "    walker_cfg = cfg.walker_config\n",
    "    env_cfg.torque_actuators = walker_cfg.torque_actuators\n",
    "    env_cfg.rescale_factor = walker_cfg.rescale_factor\n",
    "\n",
    "    # Map reference parameters directly\n",
    "    ref_cfg = cfg.reference_config\n",
    "    env_cfg.clip_length = ref_cfg.clip_length\n",
    "    env_cfg.reference_length = ref_cfg.traj_length\n",
    "    env_cfg.start_frame_range = [0, ref_cfg.random_init_range]\n",
    "\n",
    "    # Map reward terms directly\n",
    "    reward_weights = cfg.env_config.reward_weights\n",
    "\n",
    "    # Map imitation rewards\n",
    "    env_cfg.reward_terms[\"root_pos\"] = {\n",
    "        \"exp_scale\": 1.0 / reward_weights.pos_reward_exp_scale,\n",
    "        \"weight\": reward_weights.pos_reward_weight,\n",
    "    }\n",
    "\n",
    "    env_cfg.reward_terms[\"root_quat\"] = {\n",
    "        \"exp_scale\": 1.0 / reward_weights.quat_reward_exp_scale,\n",
    "        \"weight\": reward_weights.quat_reward_weight,\n",
    "    }\n",
    "\n",
    "    env_cfg.reward_terms[\"joints\"] = {\n",
    "        \"exp_scale\": 1.0 / reward_weights.joint_reward_exp_scale,\n",
    "        \"weight\": reward_weights.joint_reward_weight,\n",
    "    }\n",
    "\n",
    "    env_cfg.reward_terms[\"joints_vel\"] = {\n",
    "        \"exp_scale\": 1.0 / reward_weights.angvel_reward_exp_scale,\n",
    "        \"weight\": reward_weights.angvel_reward_weight,\n",
    "    }\n",
    "\n",
    "    env_cfg.reward_terms[\"bodies_pos\"] = {\n",
    "        \"exp_scale\": 1.0 / reward_weights.bodypos_reward_exp_scale,\n",
    "        \"weight\": reward_weights.bodypos_reward_weight,\n",
    "    }\n",
    "\n",
    "    env_cfg.reward_terms[\"end_eff\"] = {\n",
    "        \"exp_scale\": 1.0 / reward_weights.endeff_reward_exp_scale,\n",
    "        \"weight\": reward_weights.endeff_reward_weight,\n",
    "    }\n",
    "\n",
    "    # Map cost terms (these exist in default config)\n",
    "    env_cfg.reward_terms[\"control_cost\"] = {\"weight\": reward_weights.ctrl_cost_weight}\n",
    "\n",
    "    env_cfg.reward_terms[\"control_diff_cost\"] = {\n",
    "        \"weight\": reward_weights.ctrl_diff_cost_weight\n",
    "    }\n",
    "\n",
    "    # Handle energy_cost properly - it exists in default config but has different structure\n",
    "    env_cfg.reward_terms[\"energy_cost\"][\"weight\"] = reward_weights.energy_cost_weight\n",
    "\n",
    "    # Map healthy z range (exists in default config)\n",
    "    env_cfg.reward_terms[\"torso_z_range\"] = {\n",
    "        \"healthy_z_range\": tuple(reward_weights.healthy_z_range),\n",
    "        \"weight\": 1.0,  # This doesnt exist in hydra cfg\n",
    "    }\n",
    "\n",
    "    # Map penalty parameters to termination criteria (these exist in default config)\n",
    "    # env_cfg.termination_criteria[\"root_too_far\"] = {\n",
    "    #     \"max_distance\": reward_weights.too_far_dist\n",
    "    # }\n",
    "\n",
    "    # env_cfg.termination_criteria[\"pose_error\"] = {\n",
    "    #     \"max_l2_error\": reward_weights.bad_pose_dist\n",
    "    # }\n",
    "\n",
    "    # env_cfg.termination_criteria[\"root_too_rotated\"] = {\n",
    "    #     \"max_degrees\": reward_weights.bad_quat_dist\n",
    "    # }\n",
    "\n",
    "    return env_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vnl_mjx.tasks.rodent import wrappers as vnl_wrappers\n",
    "env_cfg = _track_to_vnl_cfg(cfg)\n",
    "env = vnl_wrappers.FlattenObsWrapper(imitation.Imitation(config=env_cfg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 16:24:08.671300: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-09-24 16:24:14.896670: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference observation size: 640\n",
      "Proprioceptive observation size: 226\n"
     ]
    }
   ],
   "source": [
    "reference_obs_size = env.non_proprioceptive_obs_size\n",
    "proprioceptive_obs_size = env.proprioceptive_obs_size\n",
    "print(f\"Reference observation size: {reference_obs_size}\")\n",
    "print(f\"Proprioceptive observation size: {proprioceptive_obs_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapeDtypeStruct(shape=(866,), dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_state = jax.eval_shape(env.reset, jax.random.PRNGKey(0))\n",
    "abstract_state.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore policy and make rollout functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to torque actuators\n",
      "Rescaling body tree with scale factor 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/holylabs-olveczky/Users/charleszhang/conda/mimic-mjx4/lib/python3.12/site-packages/brax/io/mjcf.py:480: UserWarning: Brax System, piplines and environments are not actively being maintained. Please see MJX for a well maintained JAX-based physics engine: https://github.com/google-deepmind/mujoco/tree/main/mjx. For a host of environments that use MJX, see: https://github.com/google-deepmind/mujoco_playground.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cfg.env_config.env_args.max_start_frame = 40\n",
    "\n",
    "env = rollout.create_environment(cfg)\n",
    "inference_fn = checkpointing.load_inference_fn(cfg, ckpt[\"policy\"])\n",
    "generate_rollout = rollout.create_rollout_generator(\n",
    "    cfg, \n",
    "    env, \n",
    "    inference_fn, \n",
    "    log_activations=True, \n",
    "    log_metrics=True, \n",
    "    log_sensor_data=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/holylabs-olveczky/Users/charleszhang/conda/mimic-mjx4/lib/python3.12/site-packages/brax/mjx/pipeline.py:77: DeprecationWarning: Accessing `contact` directly from `Data` is deprecated. Access it via `data._impl.contact` instead.\n",
      "  brax_contact = _reformat_contact(sys, data.contact)\n"
     ]
    }
   ],
   "source": [
    "step = jax.jit(env.step)\n",
    "reset = jax.jit(env.reset)\n",
    "\n",
    "state = reset(jax.random.PRNGKey(0))\n",
    "obs = env._get_proprioception(state.pipeline_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(231, dtype=int32, weak_type=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.info[\"proprioceptive_obs_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(701,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate rollouts from the checkpoint\n",
    "\n",
    "After we load the checkpoint, we can do inference on the rollout!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate a rollout imitating single clip, specified by the clip index. The first time you call the function there will be ~1-3min of compilation time, after which it will take only a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_rollout = generate_rollout(clip_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, realtime_framerate = render.render_rollout(\n",
    "    cfg, \n",
    "    single_rollout, \n",
    "    height=480,\n",
    "    width=640,\n",
    ")\n",
    "\n",
    "# save the video to disk\n",
    "media.write_video(Path(ckpt_path) / \"rollout.mp4\", frames, fps=realtime_framerate)\n",
    "media.show_video(frames, fps=realtime_framerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(ckpt_path) / \"rollout.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_to_h5py(save_path.resolve(), single_rollout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: you can load it too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = utils.load_from_h5py(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render rollout\n",
    "\n",
    "Note: Currently only works for single rollouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Generating Rollouts\n",
    "\n",
    "Alternatively, you can use `jax.vmap` to parallelize the rollout function. This is useful for performing a rollout over an entire dataset for eval/analysis purposes. We pass in a 1D array of clip indexes (`clip_idxs`) as input. \n",
    "\n",
    "The first run for this will also have a few minutes of compilation time.\n",
    "\n",
    "**Note:** `vmap` compiles based on the input shape. This means that if you use the same length for `clip_idxs`, JAX will reuse the compiled function for acceleration. However, if the input length changes, JAX will **recompile the entire function**, incurring additional overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate rollout for 5 clips simultaneously\n",
    "jit_vmap_generate_rollout = jax.jit(jax.vmap(generate_rollout))\n",
    "clip_idxs = jp.arange(0, 5)\n",
    "jit_vmap_out = jit_vmap_generate_rollout(clip_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running it with a different clip_idxs length will cause reocmpilation\n",
    "clip_idxs = jp.arange(15, 30)\n",
    "jit_vmap_out2 = jit_vmap_generate_rollout(clip_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic-mjx4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
