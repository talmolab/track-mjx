{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Environment\n",
    "Need to ensure that control steps in data is the same as control steps in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/track_mjx/lib/python3.11/site-packages/brax/v1/jumpy.py:34: DeprecationWarning: brax.v1 is deprecated and will be removed in a future release.\n",
      "  warnings.warn(\n",
      "/root/miniforge3/envs/track_mjx/lib/python3.11/site-packages/brax/v1/__init__.py:26: DeprecationWarning: brax.v1 is deprecated and will be removed in a future release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "main_path = Path().resolve().parent\n",
    "if str(main_path) not in sys.path:\n",
    "    sys.path.append(str(main_path))\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\"\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "os.environ[\"XLA_FLAGS\"] = (\n",
    "    \"--xla_gpu_enable_triton_softmax_fusion=true --xla_gpu_triton_gemm_any=True \"\n",
    ")\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "\n",
    "from absl import flags\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import uuid\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import functools\n",
    "import jax\n",
    "from typing import Dict\n",
    "import wandb\n",
    "import imageio\n",
    "from brax import envs\n",
    "from dm_control import mjcf as mjcf_dm\n",
    "from dm_control.locomotion.walkers import rescale\n",
    "\n",
    "import track_mjx.agent.custom_ppo as ppo\n",
    "from track_mjx.agent import custom_ppo\n",
    "from brax.io import model\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "from jax import numpy as jp\n",
    "\n",
    "from track_mjx.environment.task.multi_clip_tracking import MultiClipTracking\n",
    "from track_mjx.environment.task.single_clip_tracking import SingleClipTracking\n",
    "from track_mjx.io.preprocess.mjx_preprocess import process_clip_to_train\n",
    "from track_mjx.io import preprocess as preprocessing  # the pickle file needs it\n",
    "from track_mjx.environment import custom_wrappers\n",
    "from track_mjx.agent import custom_ppo_networks\n",
    "from track_mjx.agent.logging import setup_training_logging\n",
    "\n",
    "from track_mjx.environment.walker.rodent import Rodent\n",
    "from track_mjx.environment.walker.fly import Fly\n",
    "\n",
    "from track_mjx.environment.task.reward import RewardConfig\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/vast/kaiwen/track-mjx\n",
      "Using 1 GPUs\n",
      "Loading data: /root/vast/kaiwen/track-mjx/data/FlyReferenceClip.p\n",
      "self._steps_for_cur_frame: 2.0\n",
      "Environment created successfully!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "main_path = Path().resolve().parent\n",
    "print(main_path)\n",
    "if str(main_path) not in sys.path:\n",
    "    sys.path.append(str(main_path))\n",
    "    \n",
    "config_path = \"track_mjx/config/fly-mc-intention.yaml\"\n",
    "data_path = main_path / \"data/FlyReferenceClip.p\"\n",
    "\n",
    "with open(main_path / config_path, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "    \n",
    "env_args = cfg[\"env_config\"][\"env_args\"]\n",
    "env_rewards = cfg[\"env_config\"][\"reward_weights\"]\n",
    "# train_cfg = cfg[\"train_setup\"][\"train_config\"]\n",
    "walker_cfg = cfg[\"walker_config\"]\n",
    "# traj_cfg = cfg[\"reference_config\"]\n",
    "walker_type = cfg[\"walker_type\"]\n",
    "\n",
    "try:\n",
    "    n_devices = jax.device_count(backend=\"gpu\")\n",
    "    print(f\"Using {n_devices} GPUs\")\n",
    "except:\n",
    "    n_devices = 1\n",
    "    print(\"Not using GPUs\")\n",
    "\n",
    "envs.register_environment(\"rodent_single_clip\", SingleClipTracking)\n",
    "envs.register_environment(\"rodent_multi_clip\", MultiClipTracking)\n",
    "envs.register_environment(\"fly_multi_clip\", MultiClipTracking)\n",
    "\n",
    "sys.modules[\"preprocessing\"] = preprocessing\n",
    "print(f\"Loading data: {data_path}\")\n",
    "with open(data_path, \"rb\") as file:\n",
    "    reference_clip = pickle.load(file)\n",
    "\n",
    "walker_map = {\n",
    "    \"rodent\": Rodent,\n",
    "    \"fly\": Fly,\n",
    "}\n",
    "walker_class = walker_map[walker_type]\n",
    "walker = walker_class(**walker_cfg)\n",
    "\n",
    "reward_config = RewardConfig(\n",
    "    too_far_dist = env_rewards[\"too_far_dist\"],\n",
    "    bad_pose_dist = env_rewards[\"bad_pose_dist\"],\n",
    "    bad_quat_dist = env_rewards[\"bad_quat_dist\"],\n",
    "    ctrl_cost_weight = env_rewards[\"ctrl_cost_weight\"],\n",
    "    ctrl_diff_cost_weight = env_rewards[\"ctrl_diff_cost_weight\"],\n",
    "    pos_reward_weight = env_rewards[\"pos_reward_weight\"],\n",
    "    quat_reward_weight = env_rewards[\"quat_reward_weight\"],\n",
    "    joint_reward_weight = env_rewards[\"joint_reward_weight\"],\n",
    "    angvel_reward_weight = env_rewards[\"angvel_reward_weight\"],\n",
    "    bodypos_reward_weight = env_rewards[\"bodypos_reward_weight\"],\n",
    "    endeff_reward_weight = env_rewards[\"endeff_reward_weight\"],\n",
    "    healthy_z_range = env_rewards[\"healthy_z_range\"],\n",
    "    pos_reward_exp_scale = env_rewards[\"pos_reward_exp_scale\"],\n",
    "    quat_reward_exp_scale = env_rewards[\"quat_reward_exp_scale\"],\n",
    "    joint_reward_exp_scale = env_rewards[\"joint_reward_exp_scale\"],\n",
    "    angvel_reward_exp_scale = env_rewards[\"angvel_reward_exp_scale\"],\n",
    "    bodypos_reward_exp_scale = env_rewards[\"bodypos_reward_exp_scale\"],\n",
    "    endeff_reward_exp_scale = env_rewards[\"endeff_reward_exp_scale\"],\n",
    "    penalty_pos_distance_scale = jp.array(env_rewards[\"penalty_pos_distance_scale\"]),\n",
    ")\n",
    "\n",
    "env = envs.get_environment(\n",
    "    env_name=cfg[\"env_config\"][\"env_name\"],\n",
    "    reference_clip=reference_clip,\n",
    "    walker=walker,\n",
    "    reward_config=reward_config,\n",
    "    **env_args,\n",
    ")\n",
    "\n",
    "print(\"Environment created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial observation: [ 0.00230872 -0.00026385 -0.00083562 ...  0.0002936  -0.0001037\n",
      " -0.00062133]\n"
     ]
    }
   ],
   "source": [
    "rng_key = jax.random.PRNGKey(0)\n",
    "state = env.reset(rng_key)\n",
    "print(\"Initial observation:\", state.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random action: [-0.15536189  0.20095396  0.43345404  0.34053254 -0.60310864  0.24935126\n",
      "  0.48199916  0.02686977 -0.6259172  -0.20960021 -0.88146996 -0.47657156\n",
      " -0.3413067   0.63707423 -0.01317739  0.55167127  0.7239373  -0.6022897\n",
      "  0.86403346  0.06278658 -0.77842927  0.6587422   0.16663074  0.83435416\n",
      " -0.2646935   0.9968438  -0.6801503  -0.39389205  0.229635   -0.1140871\n",
      "  0.8935478   0.89969826  0.09094357  0.20086813 -0.80845547 -0.98660445]\n",
      "Next observation: [ 4.5492849e-03 -1.5185314e-03 -1.0338974e-02 ...  9.0616312e+00\n",
      " -1.9432434e+02 -9.8465431e+01]\n",
      "Reward: 1.7235847\n",
      "Done: 1.0\n",
      "Current info is: {'clip_idx': Array(10, dtype=int32), 'cur_frame': Array(12, dtype=int32), 'steps_taken_cur_frame': Array(1, dtype=int32, weak_type=True), 'summed_pos_distance': Array(2.1323545e-05, dtype=float32), 'quat_distance': Array(0.00170804, dtype=float32), 'joint_distance': Array(7.3317356, dtype=float32), 'prev_ctrl': Array([-0.15536189,  0.20095396,  0.43345404,  0.34053254, -0.60310864,\n",
      "        0.24935126,  0.48199916,  0.02686977, -0.6259172 , -0.20960021,\n",
      "       -0.88146996, -0.47657156, -0.3413067 ,  0.63707423, -0.01317739,\n",
      "        0.55167127,  0.7239373 , -0.6022897 ,  0.86403346,  0.06278658,\n",
      "       -0.77842927,  0.6587422 ,  0.16663074,  0.83435416, -0.2646935 ,\n",
      "        0.9968438 , -0.6801503 , -0.39389205,  0.229635  , -0.1140871 ,\n",
      "        0.8935478 ,  0.89969826,  0.09094357,  0.20086813, -0.80845547,\n",
      "       -0.98660445], dtype=float32), 'reference_obs_size': 935}\n",
      "Random action: [ 0.82644296 -0.036412    0.24693179 -0.8463061   0.08478642 -0.5428555\n",
      "  0.9809015  -0.18392634  0.09337163  0.356812   -0.5895541  -0.9949136\n",
      " -0.9825723  -0.21699548 -0.16539359  0.85512924 -0.53319645  0.52068496\n",
      " -0.6881263  -0.25875163  0.71233845  0.5808041  -0.8375149   0.00339603\n",
      " -0.6373503  -0.84811234 -0.9460461  -0.965261    0.09050107 -0.9076357\n",
      "  0.937443   -0.84477305  0.31344962 -0.13361359 -0.85114765 -0.5920279 ]\n",
      "Next observation: [ 1.0276884e-02 -4.3682395e-03 -1.8826693e-02 ...  2.5898895e+01\n",
      " -1.8907628e+02 -5.6420406e+01]\n",
      "Reward: 1.2070612\n",
      "Done: 1.0\n",
      "Current info is: {'clip_idx': Array(10, dtype=int32), 'cur_frame': Array(13, dtype=int32), 'steps_taken_cur_frame': Array(0, dtype=int32, weak_type=True), 'summed_pos_distance': Array(0.0001042, dtype=float32), 'quat_distance': Array(0.0086901, dtype=float32), 'joint_distance': Array(8.5961485, dtype=float32), 'prev_ctrl': Array([ 0.82644296, -0.036412  ,  0.24693179, -0.8463061 ,  0.08478642,\n",
      "       -0.5428555 ,  0.9809015 , -0.18392634,  0.09337163,  0.356812  ,\n",
      "       -0.5895541 , -0.9949136 , -0.9825723 , -0.21699548, -0.16539359,\n",
      "        0.85512924, -0.53319645,  0.52068496, -0.6881263 , -0.25875163,\n",
      "        0.71233845,  0.5808041 , -0.8375149 ,  0.00339603, -0.6373503 ,\n",
      "       -0.84811234, -0.9460461 , -0.965261  ,  0.09050107, -0.9076357 ,\n",
      "        0.937443  , -0.84477305,  0.31344962, -0.13361359, -0.85114765,\n",
      "       -0.5920279 ], dtype=float32), 'reference_obs_size': 935}\n",
      "Random action: [-0.9307914   0.6498172   0.49373746  0.8812039   0.39780402 -0.22656107\n",
      " -0.6325817   0.97939706  0.5245609   0.5162227  -0.6968732  -0.8026922\n",
      "  0.6365273  -0.46923542 -0.8810141  -0.91321135  0.861022    0.9721689\n",
      " -0.5564978   0.16871858  0.68437934 -0.484277    0.02336025 -0.8224504\n",
      "  0.5153589  -0.09465313 -0.5409272  -0.08207822 -0.42093706  0.503464\n",
      "  0.431067   -0.62808657 -0.79258513 -0.6506312  -0.1398933   0.17583752]\n",
      "Next observation: [ 1.5780414e-02 -1.0187188e-02 -2.4523387e-02 ... -7.9072578e+01\n",
      " -3.9595825e+01  1.7626146e+01]\n",
      "Reward: 0.87113714\n",
      "Done: 1.0\n",
      "Current info is: {'clip_idx': Array(10, dtype=int32), 'cur_frame': Array(13, dtype=int32), 'steps_taken_cur_frame': Array(1, dtype=int32, weak_type=True), 'summed_pos_distance': Array(0.00022028, dtype=float32), 'quat_distance': Array(0.0244645, dtype=float32), 'joint_distance': Array(8.716526, dtype=float32), 'prev_ctrl': Array([-0.9307914 ,  0.6498172 ,  0.49373746,  0.8812039 ,  0.39780402,\n",
      "       -0.22656107, -0.6325817 ,  0.97939706,  0.5245609 ,  0.5162227 ,\n",
      "       -0.6968732 , -0.8026922 ,  0.6365273 , -0.46923542, -0.8810141 ,\n",
      "       -0.91321135,  0.861022  ,  0.9721689 , -0.5564978 ,  0.16871858,\n",
      "        0.68437934, -0.484277  ,  0.02336025, -0.8224504 ,  0.5153589 ,\n",
      "       -0.09465313, -0.5409272 , -0.08207822, -0.42093706,  0.503464  ,\n",
      "        0.431067  , -0.62808657, -0.79258513, -0.6506312 , -0.1398933 ,\n",
      "        0.17583752], dtype=float32), 'reference_obs_size': 935}\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    rng_key = jax.random.PRNGKey(i)\n",
    "    action = jax.random.uniform(rng_key, shape=(env.action_size,), minval=-1.0, maxval=1.0)\n",
    "    print(\"Random action:\", action)\n",
    "    state = env.step(state, action)\n",
    "\n",
    "    print(\"Next observation:\", state.obs)\n",
    "    print(\"Reward:\", state.reward)\n",
    "    print(\"Done:\", state.done)\n",
    "    print(\"Current info is:\", state.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward after reset is: 0.0\n"
     ]
    }
   ],
   "source": [
    "state = env.reset(rng_key)\n",
    "print('reward after reset is:', state.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 1000, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env._reference_clips.position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.02204722, 0.00628723, 0.00635291], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset(rng_key)\n",
    "state.pipeline_state.qpos[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.02156236, 0.00640273, 0.00592261], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_clip = jax.tree_map(\n",
    "            lambda x: x[state.info[\"cur_frame\"]], env._get_reference_clip(state.info)\n",
    "        )\n",
    "reference_clip.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track_mjx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
