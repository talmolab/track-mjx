{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generates Rollout for existing Checkpoint\n",
    "\n",
    "This notebook will demonstrate the clean usage of the `track_mjx.analysis.rollout` module, which allows user to load the checkpoint from the previous training run, and perform a rollout of the checkpoint. This module abstracted away all the boilerplate codes for initializing the environment, and it is very clean and digestible, while customizable.\n",
    "\n",
    "## Step 1: Imports and recover the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set environment variables for rendering\n",
    "    \n",
    "%env MUJOCO_GL=egl\n",
    "%env PYOPENGL_PLATFORM=egl\n",
    "%matplotlib inline\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from track_mjx.analysis.rollout import (\n",
    "    restore_config,\n",
    "    create_rollout_generator,\n",
    "    create_environment,\n",
    "    create_inference_fn,\n",
    ")\n",
    "from jax import numpy as jp\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "# save and load\n",
    "from track_mjx.analysis.utils import save_to_h5py, load_from_h5py, get_aggregate_data, extract_clip_info\n",
    "import h5py\n",
    "\n",
    "# load snipp label\n",
    "import pickle as pkl\n",
    "\n",
    "# render\n",
    "from track_mjx.analysis.render import render_from_saved_rollout, display_video, render_with_global_and_local_pca_progression, plot_gait_analysis_horizontal\n",
    "\n",
    "# recover the config\n",
    "ckpt_path = \"/root/vast/scott-yang/track-mjx/model_checkpoints/rodent_data/ReferenceClip.p_250127_062443\"  # replace with your checkpoint path\n",
    "config = restore_config(ckpt_path)\n",
    "cfg = OmegaConf.create(config)\n",
    "\n",
    "# make some changes to the config\n",
    "# replace with absolute path to your data\n",
    "# -- your notebook may not have access to the same relative path\n",
    "cfg.data_path = \"/root/vast/scott-yang/track-mjx/data/ReferenceClip.p\"\n",
    "cfg.train_setup.checkpoint_to_restore = ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Restore policy and make rollout functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_environment(cfg)\n",
    "inference_fn = create_inference_fn(env, cfg)\n",
    "generate_rollout = create_rollout_generator(cfg[\"reference_config\"], env, inference_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate rollouts from the checkpoint!\n",
    "\n",
    "After we load the checkpoint, we can do inference on the rollout!\n",
    "\n",
    "#### Generate rollout for a single clip\n",
    "\n",
    "The following cell will generate rollout for a single clip, specified by the clip id. The first time you call the function JAX needs to complete the `JIT` compilation, which will take around 3 minutes to execute and compile. After compilation, generates the rollout will only take about 8 seconds, since it is hardware accelerated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "# first pass will take ~2m38s to run to compile\n",
    "# after complied, it only takes ~9 seconds to run\n",
    "output = generate_rollout(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Generating Rollouts\n",
    "\n",
    "Alternatively, you can use `jax.vmap` to parallelize the rollout function. To do so, pass a 1D array of clip indexes (`clip_idxs`) as input. \n",
    "\n",
    "On the first call, JAX will perform `JIT` compilation, which takes approximately **3 minutes**. Once compiled, subsequent rollouts execute in just **8 seconds**, benefiting from hardware acceleration.\n",
    "\n",
    "**Note:** `vmap` compiles based on the input shape. This means that if you use the same length for `clip_idxs`, JAX will reuse the compiled function for acceleration. However, if the input length changes, JAX will **recompile the entire function**, incurring additional overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate rollout for 5 clips simultaneously\n",
    "jit_vmap_generate_rollout = jax.jit(jax.vmap(generate_rollout))\n",
    "clip_idxs = jp.arange(0, 5)\n",
    "jit_vmap_out = jit_vmap_generate_rollout(clip_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardware acceleration: 5 clips simultaneously\n",
    "clip_idxs = jp.arange(10, 15)\n",
    "jit_vmap_out2 = jit_vmap_generate_rollout(clip_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triggers recompilation: 15 clips simultaneously\n",
    "clip_idxs = jp.arange(15, 30)\n",
    "jit_vmap_out2 = jit_vmap_generate_rollout(clip_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\n",
    "    \"/root/vast/scott-yang/rodent_rollout_info/data/clip_0.h5\", \"w\"\n",
    ") as h5file:\n",
    "    save_to_h5py(h5file, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render Rollout Videos from the Saved Rollouts\n",
    "\n",
    "We will use our pretrained then rollout data for demonstration first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rodent_rollout_dir = \"/root/vast/scott-yang/rodent_rollout_info/data\"\n",
    "fly_rollout_dir = \"/root/vast/kaiwen/track-mjx/fly_rollout_info\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the rollout file from disk\n",
    "\n",
    "Let's laodd in one rollout clip for the rodent first from our `h5` file. All the analysis can be down with just purely loading in the rollout data that we saved earlier.\n",
    "\n",
    "In here we load two pretrained then load policy to demonstrate the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\n",
    "    rodent_rollout_dir + \"/clip_1.h5\", \"r\"\n",
    ") as h5file:\n",
    "    rollout_rodent = load_from_h5py(h5file)\n",
    "\n",
    "with h5py.File(\n",
    "    fly_rollout_dir + \"/clip_1.h5\", \"r\"\n",
    ") as h5file:\n",
    "    rollout_fly = load_from_h5py(h5file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Render rollout\n",
    "\n",
    "Let's use the pure rendering function to render the rodent rollout first. The transparent wite model is the expert ghost rendering that shows the expert trajectory and the blue one is our virtual animal exerting controls to create **generative kinematics replay**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = render_from_saved_rollout(rollout_rodent, walker_name='rodent')\n",
    "display_video(frames, framerate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  can also do the same for the virtual fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = render_from_saved_rollout(rollout_fly, walker_name='fly')\n",
    "display_video(frames, framerate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Loading with multi-processing speed up\n",
    "\n",
    "The following cell traverse though the recorded rollout `.h5` file in the directly, and parse out the intentions of each episode.\n",
    "\n",
    "All of the intentions vectors are aggregated into a single matrix for PCA analysis. We will also use multiprocessing power to load in the data faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_fly = functools.partial(get_aggregate_data, \"/activations\", ['intention'], path=fly_rollout_dir)\n",
    "work_rodent = functools.partial(get_aggregate_data, \"/activations\", ['intention'], path=rodent_rollout_dir)\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    intentions_fly = list(tqdm(pool.imap(work_fly, range(499)), total=499))\n",
    "    intentions_rodent = list(tqdm(pool.imap(work_rodent, range(842)), total=842))\n",
    "\n",
    "intentions_fly = np.vstack(intentions_fly)\n",
    "intentions_rodent = np.vstack(intentions_rodent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. PCA analysis of intention & different activations\n",
    "\n",
    "We can perform some simple PCA + KMeans clustering analysis upon our intentions for both the body models, both rodent and fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "intentions_rodent = scaler.fit_transform(intentions_rodent)\n",
    "intentions_fly = scaler.fit_transform(intentions_fly)\n",
    "\n",
    "pca_rodent = PCA(n_components=2, random_state=42)\n",
    "pca_rodent = pca_rodent.fit(intentions_rodent)\n",
    "print(np.cumsum(pca_rodent.explained_variance_ratio_[:10]))\n",
    "pca_embedded_rodent = pca_rodent.transform(intentions_rodent)\n",
    "\n",
    "pca_fly = PCA(n_components=2, random_state=42)\n",
    "pca_fly = pca_fly.fit(intentions_fly)\n",
    "print(np.cumsum(pca_fly.explained_variance_ratio_[:10]))\n",
    "pca_embedded_fly = pca_fly.transform(intentions_fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_rodent = KMeans(n_clusters=4, random_state=42).fit(pca_embedded_rodent)\n",
    "rodent_labels = kmeans_rodent.labels_\n",
    "\n",
    "kmeans_fly = KMeans(n_clusters=4, random_state=42).fit(pca_embedded_fly)\n",
    "fly_labels = kmeans_fly.labels_\n",
    "\n",
    "explained_var_rodent = pca_rodent.explained_variance_ratio_ * 100\n",
    "explained_var_fly = pca_fly.explained_variance_ratio_ * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].scatter(pca_embedded_rodent[:, 0], pca_embedded_rodent[:, 1], \n",
    "                c=rodent_labels, cmap='tab10', alpha=0.6)\n",
    "axes[0].set_title(\"Rodent Clusters in PCA Space\")\n",
    "axes[0].set_xlabel(f\"PC1 ({explained_var_rodent[0]:.2f}%)\")\n",
    "axes[0].set_ylabel(f\"PC2 ({explained_var_rodent[1]:.2f}%)\")\n",
    "\n",
    "axes[1].scatter(pca_embedded_fly[:, 0], pca_embedded_fly[:, 1], \n",
    "                c=fly_labels, cmap='tab10', alpha=0.6)\n",
    "axes[1].set_title(\"Fly Clusters in PCA Space\")\n",
    "axes[1].set_xlabel(f\"PC1 ({explained_var_fly[0]:.2f}%)\")\n",
    "axes[1].set_ylabel(f\"PC2 ({explained_var_fly[1]:.2f}%)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also overlay both intentions onto the same subspace and examine the intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = np.vstack([intentions_rodent, intentions_fly])\n",
    "\n",
    "pca_shared = PCA(n_components=2, random_state=42)\n",
    "pca_shared.fit(combined_data)\n",
    "\n",
    "fly_2d_shared = pca_shared.transform(intentions_fly)\n",
    "rodent_2d_shared = pca_shared.transform(intentions_rodent)\n",
    "\n",
    "explained_var_shared = pca_shared.explained_variance_ratio_ * 100\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(fly_2d_shared[:, 0], fly_2d_shared[:, 1], alpha=0.5, label=\"Fly\", color=\"blue\")\n",
    "plt.scatter(rodent_2d_shared[:, 0], rodent_2d_shared[:, 1], alpha=0.5, label=\"Rodent\", color=\"orange\")\n",
    "\n",
    "plt.title(\"Fly vs. Rodent in a Shared PCA Space\")\n",
    "plt.xlabel(f\"PC1 ({explained_var_shared[0]:.2f}%)\")\n",
    "plt.ylabel(f\"PC2 ({explained_var_shared[1]:.2f}%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also conduct the same analysis on the activations of the rodent and the fly. For simplicity, we will render them on the same graph with 3 principal component and a 3D graph. We will need to load in all activation data first (this might take a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [['encoder','layer_0'], ['encoder','layer_1'], ['decoder','layer_0'], ['decoder','layer_1']]\n",
    "fly_activations = {}\n",
    "rodent_activations = {}\n",
    "\n",
    "work_fly = {tuple(layer): functools.partial(get_aggregate_data, \"/activations\", layer,\n",
    "                                            path=fly_rollout_dir) for layer in layers}\n",
    "work_rodent = {tuple(layer): functools.partial(get_aggregate_data, \"/activations\", layer,\n",
    "                                               path=rodent_rollout_dir) for layer in layers}\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    for layer in layers:\n",
    "        layer_key = tuple(layer)\n",
    "        activations_fly = list(tqdm(pool.imap(work_fly[layer_key], range(499)), total=499))\n",
    "        activations_rodent = list(tqdm(pool.imap(work_rodent[layer_key], range(842)), total=842))\n",
    "        fly_activations[layer_key] = np.vstack(activations_fly)\n",
    "        rodent_activations[layer_key] = np.vstack(activations_rodent)\n",
    "\n",
    "def process_and_plot_3d(activations, title, k, ax):\n",
    "    \"\"\"Performs PCA and K-Means clustering, then visualizes in 3D.\"\"\"\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_embedded = pca.fit_transform(activations)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42).fit(pca_embedded)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    sc = ax.scatter(\n",
    "        pca_embedded[:, 0], pca_embedded[:, 1], pca_embedded[:, 2],\n",
    "        c=labels, cmap=\"tab20\", alpha=0.5\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)\")\n",
    "    ax.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)\")\n",
    "    ax.set_zlabel(f\"PC3 ({pca.explained_variance_ratio_[2]*100:.2f}%)\")\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "fig, axes = plt.subplots(2, 4, figsize=(22, 10), subplot_kw={\"projection\": \"3d\"})\n",
    "for i, layer in enumerate(layers):\n",
    "    process_and_plot_3d(fly_activations[tuple(layer)], f\"Fly - {layer[0]} {layer[1]}\", k, axes[0, i])\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    process_and_plot_3d(rodent_activations[tuple(layer)], f\"Rodent - {layer[0]} {layer[1]}\", k, axes[1, i])\n",
    "\n",
    "fig.subplots_adjust(left=0.05, right=0.95, top=0.90, bottom=0.10, wspace=0.35, hspace=0.40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Clustering then tagging behaviors\n",
    "\n",
    "We can conduct behavior clustering based on labels of the clips and an majority vote mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/vast/scott-yang/vnl_ray/clips/all_snips.p\", \"rb\") as file:\n",
    "    all_snips = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_clip_ids = []\n",
    "\n",
    "for path in all_snips[\"snips_order\"]:\n",
    "    behavior, clip_id = extract_clip_info(path)\n",
    "    all_labels.append(behavior)\n",
    "    all_clip_ids.append(clip_id)\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_clip_ids = np.array(all_clip_ids)\n",
    "\n",
    "num_clips = len(all_clip_ids)\n",
    "frames_per_clip = 499\n",
    "expanded_labels = np.repeat(all_labels, frames_per_clip)\n",
    "expanded_clip_ids = np.repeat(all_clip_ids, frames_per_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "var_explained = pca_rodent.explained_variance_ratio_ * 100\n",
    "print(f\"Explained variance: PC1 = {var_explained[0]:.2f}%, PC2 = {var_explained[1]:.2f}%\")\n",
    "\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "cluster_ids = kmeans.fit_predict(pca_embedded_rodent)\n",
    "\n",
    "# Compute majority behavior for each cluster\n",
    "cluster_to_behavior = {i: [] for i in range(k)}\n",
    "for i, cluster in enumerate(cluster_ids):\n",
    "    cluster_to_behavior[cluster].append(expanded_labels[i]) \n",
    "\n",
    "cluster_majority_behavior = {}\n",
    "for cluster, behaviors in cluster_to_behavior.items():\n",
    "    # Get most frequent behavior\n",
    "    most_common_behavior = Counter(behaviors).most_common(1)[0][0]\n",
    "    cluster_majority_behavior[cluster] = most_common_behavior\n",
    "    print(f\"Cluster {cluster} → Assigned Behavior: {most_common_behavior}\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=pca_embedded_rodent[:, 0], y=pca_embedded_rodent[:, 1], hue=cluster_ids, palette=\"tab10\", alpha=0.7)\n",
    "plt.title(\"PCA Projection of Rodent Activations (K-Means Clustering)\")\n",
    "plt.xlabel(f\"PC1 ({var_explained[0]:.2f}%)\")\n",
    "plt.ylabel(f\"PC2 ({var_explained[1]:.2f}%)\")\n",
    "for cluster, behavior in cluster_majority_behavior.items():\n",
    "    cluster_center = np.mean(pca_embedded_rodent[cluster_ids == cluster], axis=0)\n",
    "    plt.text(cluster_center[0], cluster_center[1], behavior, fontsize=10, ha='center', va='center',\n",
    "             bbox=dict(facecolor='white', alpha=0.6, edgecolor='black'))\n",
    "\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. PCA clustering with Mujoco rendering\n",
    "\n",
    "We have also created functions in which we can render the global PCA graph (PCA across al clips) +  local PCA graph (PCA for one single clip) among rendering with Mujoco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id = 1\n",
    "clip_length = 599\n",
    "start = clip_id * clip_length \n",
    "end = start + clip_length\n",
    "global_subset_indices = np.arange(start, end)\n",
    "\n",
    "with h5py.File(fly_rollout_dir + f\"/clip_{clip_id}.h5\", \"r\") as h5file:\n",
    "    rollout = load_from_h5py(h5file)\n",
    "    act = get_aggregate_data(\"/activations\", ['intention'], clip_id, path=fly_rollout_dir)\n",
    "\n",
    "act = act[:599] # ref only have 600\n",
    "act = scaler.fit_transform(act)\n",
    "intentions_fly = scaler.fit_transform(intentions_fly)\n",
    "\n",
    "pca_global = PCA(n_components=2, random_state=42)\n",
    "pca_local = PCA(n_components=2, random_state=42)\n",
    "global_embedding = pca_global.fit(intentions_fly).transform(intentions_fly)\n",
    "local_embedding = pca_local.fit(act).transform(act)\n",
    "global_labels = KMeans(n_clusters=4, random_state=42).fit(global_embedding).labels_\n",
    "local_labels = KMeans(n_clusters=4, random_state=42).fit(local_embedding).labels_\n",
    "\n",
    "frames = render_with_global_and_local_pca_progression(\n",
    "    rollout=rollout,\n",
    "    walker_name=\"fly\",\n",
    "    pca_global=global_embedding, \n",
    "    cluster_global=global_labels,\n",
    "    global_subset_indices=global_subset_indices,\n",
    "    pca_local=local_embedding,\n",
    "    cluster_local=local_labels,\n",
    "    var_lcoal=pca_global.explained_variance_ratio_,\n",
    "    var_global=pca_local.explained_variance_ratio_,\n",
    ")\n",
    "display_video(frames, framerate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id = 1\n",
    "clip_length = 499\n",
    "start = clip_id * clip_length \n",
    "end = start + clip_length\n",
    "global_subset_indices = np.arange(start, end)\n",
    "\n",
    "with h5py.File(rodent_rollout_dir + f\"/clip_{clip_id}.h5\", \"r\") as h5file:\n",
    "    rollout = load_from_h5py(h5file)\n",
    "    act = get_aggregate_data(\"/activations\", ['intention'], clip_id, path=rodent_rollout_dir)\n",
    "\n",
    "act = scaler.fit_transform(act)\n",
    "intention_rodent = scaler.fit_transform(intentions_rodent)\n",
    "\n",
    "pca_global = PCA(n_components=2, random_state=42)\n",
    "pca_local = PCA(n_components=2, random_state=42)\n",
    "global_embedding = pca_global.fit(intention_rodent).transform(intention_rodent)\n",
    "local_embedding = pca_local.fit(act).transform(act)\n",
    "global_labels = KMeans(n_clusters=4, random_state=42).fit(global_embedding).labels_\n",
    "local_labels = KMeans(n_clusters=4, random_state=42).fit(local_embedding).labels_\n",
    "\n",
    "frames = render_with_global_and_local_pca_progression(\n",
    "    rollout=rollout,\n",
    "    walker_name=\"rodent\",\n",
    "    pca_global=global_embedding, \n",
    "    cluster_global=global_labels,\n",
    "    global_subset_indices=global_subset_indices,\n",
    "    pca_local=local_embedding,\n",
    "    cluster_local=local_labels,\n",
    "    var_lcoal=pca_fly.explained_variance_ratio_,\n",
    "    var_global=pca_local.explained_variance_ratio_,\n",
    ")\n",
    "display_video(frames, framerate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7. Visualizing Gait Cycles\n",
    "\n",
    "We can visualize the gait cycle of each of the virtuak rodent, just like activation, we can load in the qposes for each first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_fly = functools.partial(get_aggregate_data, \"/qposes_rollout\", [], path=fly_rollout_dir)\n",
    "work_rodent = functools.partial(get_aggregate_data, \"/qposes_rollout\", [], path=rodent_rollout_dir)\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    qpos_fly = list(tqdm(pool.imap(work_fly, range(30)), total=30))\n",
    "    qpos_rodent = list(tqdm(pool.imap(work_rodent, range(1, 842)), total=841))\n",
    "\n",
    "qpos_fly = np.vstack(qpos_fly)\n",
    "qpos_rodent = np.vstack(qpos_rodent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fly_leg_indices = [6, 12, 18, 24, 30, 36]\n",
    "fly_leg_labels = [\"Front Leg (T1) Left\", \"Front Leg (T1) Right\",\n",
    "                  \"Middle Leg (T2) Left\", \"Middle Leg (T2) Right\",\n",
    "                  \"Hind Leg (T3) Left\", \"Hind Leg (T3) Right\"]\n",
    "plot_gait_analysis_horizontal(qpos_fly, fly_leg_indices, fly_leg_labels, dt=1/500, \n",
    "                              clip_start=0, num_clips=3, timesteps_per_clip=599, \n",
    "                              color='blue', title_prefix=\"Fly - Gait Analysis\")\n",
    "\n",
    "rodent_leg_indices = [12, 18, 59, 67]\n",
    "rodent_leg_labels = [\"Hind Left (Toe)\", \"Hind Right (Toe)\", \"Fore Left (Finger)\", \"Fore Right (Finger)\"]\n",
    "plot_gait_analysis_horizontal(qpos_rodent, rodent_leg_indices, rodent_leg_labels, dt=1/50, \n",
    "                              clip_start=0, num_clips=3, timesteps_per_clip=250, \n",
    "                              color='red', title_prefix=\"Rodent - Gait Analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track-mjx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
