{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Environment\n",
    "Need to ensure that control steps in data is the same as control steps in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/track_mjx/lib/python3.11/site-packages/brax/v1/jumpy.py:34: DeprecationWarning: brax.v1 is deprecated and will be removed in a future release.\n",
      "  warnings.warn(\n",
      "/root/miniforge3/envs/track_mjx/lib/python3.11/site-packages/brax/v1/__init__.py:26: DeprecationWarning: brax.v1 is deprecated and will be removed in a future release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "main_path = Path().resolve().parent\n",
    "if str(main_path) not in sys.path:\n",
    "    sys.path.append(str(main_path))\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\"\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "os.environ[\"XLA_FLAGS\"] = (\n",
    "    \"--xla_gpu_enable_triton_softmax_fusion=true --xla_gpu_triton_gemm_any=True \"\n",
    ")\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "\n",
    "from absl import flags\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import uuid\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import functools\n",
    "import jax\n",
    "from typing import Dict\n",
    "import wandb\n",
    "import imageio\n",
    "from brax import envs\n",
    "from dm_control import mjcf as mjcf_dm\n",
    "from dm_control.locomotion.walkers import rescale\n",
    "\n",
    "import track_mjx.agent.custom_ppo as ppo\n",
    "from track_mjx.agent import custom_ppo\n",
    "from brax.io import model\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "from jax import numpy as jp\n",
    "\n",
    "from track_mjx.environment.task.multi_clip_tracking import MultiClipTracking\n",
    "from track_mjx.environment.task.single_clip_tracking import SingleClipTracking\n",
    "from track_mjx.io.preprocess.mjx_preprocess import process_clip_to_train\n",
    "from track_mjx.io import preprocess as preprocessing  # the pickle file needs it\n",
    "from track_mjx.environment import custom_wrappers\n",
    "from track_mjx.agent import custom_ppo_networks\n",
    "from track_mjx.agent.logging import setup_training_logging\n",
    "\n",
    "from track_mjx.environment.walker.rodent import Rodent\n",
    "from track_mjx.environment.walker.fly import Fly\n",
    "\n",
    "from track_mjx.environment.task.reward import RewardConfig\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to flip the mj.timesetep thing off in single clip tracking for this to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/vast/kaiwen/track-mjx\n",
      "Using 1 GPUs\n",
      "Loading data: /root/vast/kaiwen/track-mjx/data/FlyReferenceClip.p\n",
      "self._steps_for_cur_frame: 1.0\n",
      "Environment created successfully!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "def convert_to_number(value):\n",
    "    \"\"\"\n",
    "    Recursively converts string representations of numbers to actual numeric types.\n",
    "    Handles integers, floats, and scientific notation (e.g., '1e-3').\n",
    "    \"\"\"\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            # Attempt to convert to integer\n",
    "            if value.isdigit():\n",
    "                return int(value)\n",
    "            # Attempt to convert to float (handles '1.0', '1e-3', etc.)\n",
    "            return float(value)\n",
    "        except ValueError:\n",
    "            # Return the original string if it cannot be converted\n",
    "            return value\n",
    "    elif isinstance(value, dict):\n",
    "        return {k: convert_to_number(v) for k, v in value.items()}\n",
    "    elif isinstance(value, list):\n",
    "        return [convert_to_number(item) for item in value]\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "main_path = Path().resolve().parent\n",
    "print(main_path)\n",
    "if str(main_path) not in sys.path:\n",
    "    sys.path.append(str(main_path))\n",
    "    \n",
    "config_path = \"track_mjx/config/fly-mc-intention.yaml\"\n",
    "data_path = main_path / \"data/FlyReferenceClip.p\"\n",
    "\n",
    "with open(main_path / config_path, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "    \n",
    "cfg = convert_to_number(cfg)\n",
    "    \n",
    "env_args = cfg[\"env_config\"][\"env_args\"]\n",
    "env_rewards = cfg[\"env_config\"][\"reward_weights\"]\n",
    "# train_cfg = cfg[\"train_setup\"][\"train_config\"]\n",
    "walker_cfg = cfg[\"walker_config\"]\n",
    "traj_cfg = cfg[\"reference_config\"]\n",
    "walker_type = cfg[\"walker_type\"]\n",
    "\n",
    "try:\n",
    "    n_devices = jax.device_count(backend=\"gpu\")\n",
    "    print(f\"Using {n_devices} GPUs\")\n",
    "except:\n",
    "    n_devices = 1\n",
    "    print(\"Not using GPUs\")\n",
    "\n",
    "envs.register_environment(\"rodent_single_clip\", SingleClipTracking)\n",
    "envs.register_environment(\"rodent_multi_clip\", MultiClipTracking)\n",
    "envs.register_environment(\"fly_multi_clip\", MultiClipTracking)\n",
    "\n",
    "sys.modules[\"preprocessing\"] = preprocessing\n",
    "print(f\"Loading data: {data_path}\")\n",
    "with open(data_path, \"rb\") as file:\n",
    "    reference_clip = pickle.load(file)\n",
    "\n",
    "walker_map = {\n",
    "    \"rodent\": Rodent,\n",
    "    \"fly\": Fly,\n",
    "}\n",
    "walker_class = walker_map[walker_type]\n",
    "walker = walker_class(**walker_cfg)\n",
    "\n",
    "reward_config = RewardConfig(\n",
    "    too_far_dist = env_rewards[\"too_far_dist\"],\n",
    "    bad_pose_dist = env_rewards[\"bad_pose_dist\"],\n",
    "    bad_quat_dist = env_rewards[\"bad_quat_dist\"],\n",
    "    ctrl_cost_weight = env_rewards[\"ctrl_cost_weight\"],\n",
    "    ctrl_diff_cost_weight = env_rewards[\"ctrl_diff_cost_weight\"],\n",
    "    pos_reward_weight = env_rewards[\"pos_reward_weight\"],\n",
    "    quat_reward_weight = env_rewards[\"quat_reward_weight\"],\n",
    "    joint_reward_weight = env_rewards[\"joint_reward_weight\"],\n",
    "    angvel_reward_weight = env_rewards[\"angvel_reward_weight\"],\n",
    "    bodypos_reward_weight = env_rewards[\"bodypos_reward_weight\"],\n",
    "    endeff_reward_weight = env_rewards[\"endeff_reward_weight\"],\n",
    "    healthy_z_range = env_rewards[\"healthy_z_range\"],\n",
    "    pos_reward_exp_scale = env_rewards[\"pos_reward_exp_scale\"],\n",
    "    quat_reward_exp_scale = env_rewards[\"quat_reward_exp_scale\"],\n",
    "    joint_reward_exp_scale = env_rewards[\"joint_reward_exp_scale\"],\n",
    "    angvel_reward_exp_scale = env_rewards[\"angvel_reward_exp_scale\"],\n",
    "    bodypos_reward_exp_scale = env_rewards[\"bodypos_reward_exp_scale\"],\n",
    "    endeff_reward_exp_scale = env_rewards[\"endeff_reward_exp_scale\"],\n",
    "    penalty_pos_distance_scale = jp.array(env_rewards[\"penalty_pos_distance_scale\"]),\n",
    ")\n",
    "\n",
    "env = envs.get_environment(\n",
    "    env_name=cfg[\"env_config\"][\"env_name\"],\n",
    "    reference_clip=reference_clip,\n",
    "    walker=walker,\n",
    "    reward_config=reward_config,\n",
    "    **env_args,\n",
    "    **traj_cfg,\n",
    ")\n",
    "\n",
    "print(\"Environment created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial observation: [ 0.00235102 -0.00046809 -0.00072988 ...  0.0002936  -0.0001037\n",
      " -0.00062133]\n"
     ]
    }
   ],
   "source": [
    "rng_key = jax.random.PRNGKey(0)\n",
    "state = env.reset(rng_key)\n",
    "print(\"Initial observation:\", state.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clip_idx': Array(10, dtype=int32),\n",
       " 'cur_frame': Array(36, dtype=int32),\n",
       " 'steps_taken_cur_frame': 0,\n",
       " 'summed_pos_distance': 0.0,\n",
       " 'quat_distance': 0.0,\n",
       " 'joint_distance': 0.0,\n",
       " 'prev_ctrl': Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=float32),\n",
       " 'reference_obs_size': 935}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    rng_key = jax.random.PRNGKey(i)\n",
    "    action = jax.random.uniform(rng_key, shape=(env.action_size,), minval=-1.0, maxval=1.0)\n",
    "    print(\"Random action:\", action)\n",
    "    state = env.step(state, action)\n",
    "\n",
    "    print(\"Next observation:\", state.obs)\n",
    "    print(\"Reward:\", state.reward)\n",
    "    print(\"Done:\", state.done)\n",
    "    print(\"Current info is:\", state.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset(rng_key)\n",
    "print('reward after reset is:', state.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env._reference_clips.position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset(rng_key)\n",
    "state.pipeline_state.qpos[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_clip = jax.tree_map(\n",
    "            lambda x: x[state.info[\"cur_frame\"]], env._get_reference_clip(state.info)\n",
    "        )\n",
    "reference_clip.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track_mjx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
