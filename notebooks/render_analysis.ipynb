{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw: Rendering & Analysis (Fly & Rodent)\n",
    "\n",
    "- Modified from Scott's notebook\n",
    "\n",
    "This notebook will show you how to load the saved rollout, and create a rendering video from that, with further visual analysis pipeline to visualize the agents, i.e. temporal dynamics of the intentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "main_path = Path().resolve().parent\n",
    "if str(main_path) not in sys.path:\n",
    "    sys.path.append(str(main_path))\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "from track_mjx.environment.task.multi_clip_tracking import MultiClipTracking\n",
    "from track_mjx.environment.walker.rodent import Rodent\n",
    "\n",
    "import mujoco\n",
    "from pathlib import Path\n",
    "from dm_control import mjcf as mjcf_dm\n",
    "from dm_control.locomotion.walkers import rescale\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "import multiprocessing as mp\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendering Related Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_backend_context(func):\n",
    "    \"\"\"\n",
    "    Decorator to switch to a headless backend during function execution.\n",
    "    \"\"\"\n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        orig_backend = matplotlib.get_backend()\n",
    "        matplotlib.use(\"Agg\")  # Switch to headless 'Agg' to inhibit figure rendering.\n",
    "        # Code to execute BEFORE the original function\n",
    "        result = func(*args, **kwargs)\n",
    "        # Code to execute AFTER the original function\n",
    "        plt.close(\"all\")  # Figure auto-closing upon backend switching is deprecated.\n",
    "        matplotlib.use(orig_backend)\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def render_from_saved_rollout(\n",
    "    rollout: dict,\n",
    "    walker_name: str,\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Render a rollout from saved qposes.\n",
    "\n",
    "    Args:\n",
    "        rollout (dict): A dictionary containing the qposes of the reference and rollout trajectories.\n",
    "\n",
    "    Returns:\n",
    "        list: list of frames of the rendering\n",
    "    \"\"\"\n",
    "    qposes_ref, qposes_rollout = rollout[\"qposes_ref\"], rollout[\"qposes_rollout\"]\n",
    "    # print(len(qposes_rollout))\n",
    "    # need to change to the new xml file\n",
    "    \n",
    "    if walker_name == \"rodent\":\n",
    "        pair_render_xml_path = (\n",
    "            #\"/root/vast/kaiwen/track-mjx/track_mjx/environment/walker/assets/fruitfly/fruitfly_force_pair.xml\"\n",
    "            \"/root/vast/scott-yang/track-mjx/track_mjx/environment/walker/assets/rodent/rodent_ghostpair_scale080.xml\"\n",
    "        )\n",
    "        camera_name = \"close_profile\"\n",
    "        \n",
    "        spec = mujoco.MjSpec()\n",
    "        spec = spec.from_file(str(pair_render_xml_path))\n",
    "        \n",
    "        # in training scaled by this amount as well\n",
    "        for geom in spec.geoms:\n",
    "            if geom.size is not None:\n",
    "                geom.size *= 0.95\n",
    "            if geom.pos is not None:\n",
    "                geom.pos *= 0.95\n",
    "    else:\n",
    "        pair_render_xml_path = (\n",
    "            \"/root/vast/kaiwen/track-mjx/track_mjx/environment/walker/assets/fruitfly/fruitfly_force_pair.xml\"\n",
    "        )\n",
    "        camera_name = \"track1-0\"\n",
    "        \n",
    "        spec = mujoco.MjSpec()\n",
    "        spec = spec.from_file(str(pair_render_xml_path))\n",
    "        \n",
    "        # in training scaled by this amount as well\n",
    "        for geom in spec.geoms:\n",
    "            if geom.size is not None:\n",
    "                geom.size *= 1\n",
    "            if geom.pos is not None:\n",
    "                geom.pos *= 1\n",
    "\n",
    "    mj_model = spec.compile()\n",
    "\n",
    "    mj_model.opt.solver = {\n",
    "        \"cg\": mujoco.mjtSolver.mjSOL_CG,\n",
    "        \"newton\": mujoco.mjtSolver.mjSOL_NEWTON,\n",
    "    }[\"cg\"]\n",
    "\n",
    "    mj_model.opt.iterations = 6\n",
    "    mj_model.opt.ls_iterations = 6\n",
    "    mj_data = mujoco.MjData(mj_model)\n",
    "\n",
    "    site_id = [\n",
    "        mj_model.site(i).id\n",
    "        for i in range(mj_model.nsite)\n",
    "        if \"-0\" in mj_model.site(i).name\n",
    "    ]\n",
    "    for id in site_id:\n",
    "        mj_model.site(id).rgba = [1, 0, 0, 1]\n",
    "    \n",
    "    for i in range(mj_model.ngeom):\n",
    "        geom_name = mj_model.geom(i).name\n",
    "        if \"-1\" in geom_name:  # ghost\n",
    "            mj_model.geom(i).rgba = [\n",
    "                1,\n",
    "                1,\n",
    "                1,\n",
    "                0.5,\n",
    "            ]  # White color, 50% transparent\n",
    "\n",
    "    # visual mujoco rendering\n",
    "    scene_option = mujoco.MjvOption()\n",
    "    scene_option.sitegroup[:] = [1, 1, 1, 1, 1, 0]\n",
    "    # save rendering and log to wandb\n",
    "    mujoco.mj_kinematics(mj_model, mj_data)\n",
    "    renderer = mujoco.Renderer(mj_model, height=480, width=640)\n",
    "    frames = []\n",
    "    print(\"MuJoCo Rendering...\")\n",
    "    for qpos1, qpos2 in tqdm(zip(qposes_rollout, qposes_ref), total=len(qposes_rollout)):\n",
    "        mj_data.qpos = np.append(qpos1, qpos2)\n",
    "        mujoco.mj_forward(mj_model, mj_data)\n",
    "        renderer.update_scene(\n",
    "            mj_data,\n",
    "            camera=camera_name\n",
    "        )\n",
    "        pixels = renderer.render()\n",
    "        frames.append(pixels)\n",
    "        \n",
    "    return frames\n",
    "\n",
    "\n",
    "def plot_pca_intention(\n",
    "    idx,\n",
    "    episode_start,\n",
    "    pca_projections: np.ndarray,\n",
    "    clip_idx: int,\n",
    "    feature_name: str,\n",
    "    n_components: int = 4,\n",
    "    terminated=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    plot pca intention progression of the episode\n",
    "    Args:\n",
    "        idx: the current timestep\n",
    "        episode_start: the start timestep of the episode\n",
    "        pca_projections: the pca projection of the episode, shape (timestep, n_components)\n",
    "        clip_idx: the clip index\n",
    "        feature_name: the feature name\n",
    "        n_components: the number of pca components to plot\n",
    "        ylim: the y-axis limit\n",
    "        terminated: whether the episode is terminated\n",
    "\n",
    "    \"\"\"\n",
    "    max_y = np.max(list(pca_projections[:, :n_components]))\n",
    "    min_y = np.min(list(pca_projections[:, :n_components]))\n",
    "    y_lim = (min_y - 0.2, max_y + 0.2)\n",
    "    window_size = 530\n",
    "    idx_in_this_episode = idx - episode_start  # the current timestep in this episode\n",
    "    plt.figure(figsize=(9.6, 4.8))\n",
    "    for pc_ind in range(n_components):\n",
    "        # Plot the PCA projection of the episode\n",
    "        plt.plot(\n",
    "            pca_projections[episode_start:idx, pc_ind],\n",
    "            label=f\"PC {pc_ind} ({pca.explained_variance_ratio_[pc_ind]*100:.1f}%)\",\n",
    "        )\n",
    "        plt.scatter(idx - episode_start, pca_projections[idx - 1, pc_ind])\n",
    "    if terminated:\n",
    "        # Mark the episode termination\n",
    "        plt.axvline(x=idx - episode_start, color=\"r\", linestyle=\"-\")\n",
    "        plt.text(\n",
    "            idx - episode_start - 8,  # Adjust the x-offset as needed\n",
    "            sum(y_lim) / 2,  # Adjust the y-position as needed\n",
    "            \"Episode Terminated\",\n",
    "            color=\"r\",\n",
    "            rotation=90,\n",
    "        )  # Rotate the text vertically\n",
    "    if idx_in_this_episode <= window_size:\n",
    "        plt.xlim(0, window_size)\n",
    "    else:\n",
    "        plt.xlim(idx_in_this_episode - window_size, idx_in_this_episode)  # dynamically move xlim as time progress\n",
    "    plt.ylim(*y_lim)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.title(f\"PCA {feature_name} Progression for Clip {clip_idx}\")  # TODO make it configurable\n",
    "    # Get the current figure\n",
    "    fig = plt.gcf()\n",
    "    # Create a canvas for rendering\n",
    "    canvas = FigureCanvasAgg(fig)\n",
    "    # Render the canvas to a buffer\n",
    "    canvas.draw()\n",
    "    s, (width, height) = canvas.print_to_buffer()\n",
    "    # Convert the buffer to a PIL Image\n",
    "    image = Image.frombytes(\"RGBA\", (width, height), s)\n",
    "    rgb_array = np.array(image.convert(\"RGB\"))\n",
    "    return rgb_array\n",
    "\n",
    "\n",
    "def render_with_pca_progression(\n",
    "    rollout: dict, pca_projections: np.ndarray, n_components: int = 4, feature_name: str = \"ctrl\"\n",
    "):\n",
    "    \"\"\"\n",
    "    render with the rewards progression graph concat alongside with the rendering\n",
    "    \"\"\"\n",
    "    frames_mujoco = render_from_saved_rollout(rollout)[1:]\n",
    "    # skip the first frame, since we don't have intention for the first frame\n",
    "    orig_backend = matplotlib.get_backend()\n",
    "    matplotlib.use(\"Agg\")  # Switch to headless 'Agg' to inhibit figure rendering.\n",
    "    clip_idx = int(rollout[\"info\"][0][\"clip_idx\"])\n",
    "    worker = functools.partial(\n",
    "        plot_pca_intention,\n",
    "        episode_start=0,\n",
    "        clip_idx=clip_idx,\n",
    "        pca_projections=pca_embedded,\n",
    "        n_components=n_components,\n",
    "        feature_name=feature_name,\n",
    "    )\n",
    "    print(\"Rendering with PCA progression...\")\n",
    "    # Use multiprocessing to parallelize the rendering of the reward graph\n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        frames_pca = pool.map(worker, range(len(rollout[\"qposes_rollout\"])))\n",
    "    concat_frames = []\n",
    "    episode_start = 0\n",
    "    # implement reset logics of the reward graph too.\n",
    "    print(\"Concatenating frames...\")\n",
    "    for idx, frame in tqdm(enumerate(frames_mujoco)):\n",
    "        concat_frames.append(np.hstack([frame, frames_pca[idx]]))\n",
    "    reward_plot = plot_pca_intention(\n",
    "        len(frames_mujoco) - 1, episode_start, pca_projections, clip_idx, feature_name, n_components, terminated=True\n",
    "    )\n",
    "    plt.close(\"all\")  # Figure auto-closing upon backend switching is deprecated.\n",
    "    matplotlib.use(orig_backend)\n",
    "    for _ in range(50):\n",
    "        concat_frames.append(np.hstack([frames_mujoco[-1], reward_plot]))  # create stoppage when episode terminates\n",
    "    return concat_frames\n",
    "\n",
    "\n",
    "def display_video(frames, framerate=30):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        frames (array): (n_frames, height, width, 3)\n",
    "        framerate (int): the framerate of the video\n",
    "    \"\"\"\n",
    "    height, width, _ = frames[0].shape\n",
    "    dpi = 70\n",
    "    orig_backend = matplotlib.get_backend()\n",
    "    matplotlib.use(\"Agg\")  # Switch to headless 'Agg' to inhibit figure rendering.\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "    plt.close(\"all\")  # Figure auto-closing upon backend switching is deprecated.\n",
    "    matplotlib.use(orig_backend)  # Switch back to the original backend.\n",
    "    ax.set_axis_off()\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    im = ax.imshow(frames[0])\n",
    "\n",
    "    def update(frame):\n",
    "        im.set_data(frame)\n",
    "        return [im]\n",
    "\n",
    "    interval = 1000 / framerate\n",
    "    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames, interval=interval, blit=True, repeat=False)\n",
    "    return HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the rollout file from the `.h5` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def load_from_h5py(file, group_path=\"/\") -> dict:\n",
    "    \"\"\"\n",
    "    Load a pytree structure from an HDF5 file.\n",
    "\n",
    "    Args:\n",
    "        file (h5py.File): An open HDF5 file object.\n",
    "        group_path (str): The HDF5 group path to read data from.\n",
    "\n",
    "    Returns:\n",
    "        The reconstructed data structure.\n",
    "    \"\"\"\n",
    "    group = file[group_path]\n",
    "    if isinstance(group, h5py.Dataset):\n",
    "        return group[()]  # Read dataset value\n",
    "    elif isinstance(group, h5py.Group):\n",
    "        if all(k.isdigit() for k in group.keys()):  # Likely a list\n",
    "            return [load_from_h5py(file, f\"{group_path}/{k}\") for k in sorted(group.keys(), key=int)]\n",
    "        else:  # Dictionary-like group\n",
    "            return {k: load_from_h5py(file, f\"{group_path}/{k}\") for k in group.keys()}\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported group type: {type(group)}\")\n",
    "\n",
    "# Example usage\n",
    "with h5py.File(\"/root/vast/kaiwen/track-mjx/rodent_rollout_info/clip_0.h5\", \"r\") as h5file:\n",
    "    rollout = load_from_h5py(h5file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load in both of the fly and the rodent to do comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly get out the activations\n",
    "with h5py.File(\"/root/vast/kaiwen/track-mjx/rodent_rollout_info/clip_1.h5\", \"r\") as h5file:\n",
    "    activations_fly = load_from_h5py(h5file, group_path=\"/activations\")\n",
    "    intentions_fly = [a[\"intention\"] for a in activations_fly]\n",
    "\n",
    "with h5py.File(\"/root/vast/scott-yang/rodent_rollout_info/data/clip_1.h5\", \"r\") as h5file:\n",
    "    activations_rodent = load_from_h5py(h5file, group_path=\"/activations\")\n",
    "    intentions_rodent = [a[\"intention\"] for a in activations_rodent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_fly[0][\"intention\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: PCA for all intentions across rollout\n",
    "\n",
    "The following cell traverse though the recorded rollout `.h5` file in the directly, and parse out the intentions of each episode. All of the intentions vectors are aggregated into a single matrix for PCA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregate_data(group_path, keys: List[str], clip_idx: int, path: str):\n",
    "    \"\"\"\n",
    "    Get the aggregate data from the hdf5 file\n",
    "    \"\"\"\n",
    "    with h5py.File(path + f'/clip_{clip_idx}.h5', \"r\") as h5file:\n",
    "        data = load_from_h5py(h5file, group_path=group_path)\n",
    "        for key in keys:\n",
    "            if type(data) == list and type(data[0]) == dict:\n",
    "                data = [d[key] for d in data]\n",
    "            elif type(data) == dict:\n",
    "                data = data[key]\n",
    "            else:\n",
    "                raise ValueError(\"Data structure not supported\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiProcessing SpeedUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this will take 0.63 * 850 = 535 seconds = 8.9 minutes to run, if I run it in a ordinary for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# if I wanna get the activations for the decoder layer 0 of clip 1\n",
    "get_aggregate_data(\"/activations\", [\"intention\"], 1, path=f\"/root/vast/kaiwen/track-mjx/rodent_rollout_info\")\n",
    "\n",
    "# this will take 0.63 * 850 = 535 seconds = 8.9 minutes to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " However, if I multiprocessing the IO call, we only need 26 seconds to complete the call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "work_fly = functools.partial(get_aggregate_data, \"/activations\", ['intention'], path=f\"/root/vast/kaiwen/track-mjx/rodent_rollout_info\")\n",
    "work_rodent = functools.partial(get_aggregate_data, \"/activations\", ['intention'], path=f\"/root/vast/scott-yang/rodent_rollout_info/data/\")\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    activations_fly = list(tqdm(pool.imap(work_fly, range(499)), total=499))\n",
    "    activations_rodent = list(tqdm(pool.imap(work_rodent, range(842)), total=842))\n",
    "\n",
    "activations_fly = np.vstack(activations_fly)\n",
    "activations_rodent = np.vstack(activations_rodent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_fly.shape, activations_rodent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D PCA + Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "activations_rodent = scaler.fit_transform(activations_rodent)\n",
    "activations_fly = scaler.fit_transform(activations_fly)\n",
    "\n",
    "pca_rodent = PCA()\n",
    "\n",
    "pca_rodent = pca_rodent.fit(activations_rodent)\n",
    "print(np.cumsum(pca_rodent.explained_variance_ratio_[:10]))\n",
    "pca_embedded_rodent = pca_rodent.transform(activations_rodent)\n",
    "\n",
    "pca_fly = PCA()\n",
    "\n",
    "pca_fly = pca_fly.fit(activations_fly)\n",
    "print(np.cumsum(pca_fly.explained_variance_ratio_[:10]))\n",
    "pca_embedded_fly = pca_fly.transform(activations_fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pca_embedded_rodent[:, 0], pca_embedded_rodent[:, 1], c=np.arange(420158), cmap=\"tab20\", alpha=0.5)\n",
    "plt.xlabel(f\"PCA 1 {pca_rodent.explained_variance_ratio_[0]*100:.2f}%\")\n",
    "plt.ylabel(f\"PCA 2 {pca_rodent.explained_variance_ratio_[1]*100:.2f}%\")\n",
    "plt.title(\"PCA of intentions across all episodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pca_embedded_fly[:, 0], pca_embedded_fly[:, 1], c=np.arange(498501), cmap=\"tab20\", alpha=0.5)\n",
    "plt.xlabel(f\"PCA 1 {pca_fly.explained_variance_ratio_[0]*100:.2f}%\")\n",
    "plt.ylabel(f\"PCA 2 {pca_fly.explained_variance_ratio_[1]*100:.2f}%\")\n",
    "plt.title(\"PCA of intentions across all episodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_rodent = PCA(n_components=3)\n",
    "pca_embedded_fly = pca_rodent.fit_transform(activations_rodent) \n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "N = pca_embedded_fly.shape[0]\n",
    "c_values = np.arange(N)\n",
    "\n",
    "sc = ax.scatter(\n",
    "    pca_embedded_fly[:, 0],\n",
    "    pca_embedded_fly[:, 1],\n",
    "    pca_embedded_fly[:, 2],\n",
    "    c=c_values,\n",
    "    cmap=\"tab20\",\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "cb = plt.colorbar(sc, ax=ax, shrink=0.6)\n",
    "cb.set_label(\"Sample Index\")\n",
    "\n",
    "ax.set_xlabel(f\"PC1 ({pca_rodent.explained_variance_ratio_[0]*100:.2f}%)\")\n",
    "ax.set_ylabel(f\"PC2 ({pca_rodent.explained_variance_ratio_[1]*100:.2f}%)\")\n",
    "ax.set_zlabel(f\"PC3 ({pca_rodent.explained_variance_ratio_[2]*100:.2f}%)\")\n",
    "\n",
    "ax.set_title(\"3D PCA of intentions across all episodes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_fly = PCA(n_components=3)\n",
    "pca_embedded_fly = pca_fly.fit_transform(activations_fly) \n",
    "\n",
    "k = 6\n",
    "kmeans_fly = KMeans(n_clusters=k, random_state=42).fit(pca_embedded_fly)\n",
    "fly_labels = kmeans_fly.labels_\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "N = pca_embedded_fly.shape[0]\n",
    "c_values = np.arange(N)\n",
    "\n",
    "sc = ax.scatter(\n",
    "    pca_embedded_fly[:, 0],\n",
    "    pca_embedded_fly[:, 1],\n",
    "    pca_embedded_fly[:, 2],\n",
    "    c=fly_labels,\n",
    "    cmap=\"tab20\",\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "cb = plt.colorbar(sc, ax=ax, shrink=0.6)\n",
    "cb.set_label(\"Sample Index\")\n",
    "\n",
    "ax.set_xlabel(f\"PC1 ({pca_fly.explained_variance_ratio_[0]*100:.2f}%)\")\n",
    "ax.set_ylabel(f\"PC2 ({pca_fly.explained_variance_ratio_[1]*100:.2f}%)\")\n",
    "ax.set_zlabel(f\"PC3 ({pca_fly.explained_variance_ratio_[2]*100:.2f}%)\")\n",
    "\n",
    "ax.set_title(\"3D PCA of intentions across all episodes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# pca_fly = PCA(n_components=3)\n",
    "# pca_embedded_fly = pca_fly.fit_transform(activations_fly) \n",
    "\n",
    "# k = 6\n",
    "# kmeans_fly = KMeans(n_clusters=k, random_state=42).fit(pca_embedded_fly)\n",
    "# fly_labels = kmeans_fly.labels_\n",
    "\n",
    "# fig = px.scatter_3d(\n",
    "#     x=pca_embedded_fly[:, 0],\n",
    "#     y=pca_embedded_fly[:, 1],\n",
    "#     z=pca_embedded_fly[:, 2],\n",
    "#     color=fly_labels.astype(str),\n",
    "#     labels={\n",
    "#         \"x\": f\"PC1 ({pca_fly.explained_variance_ratio_[0]*100:.2f}%)\",\n",
    "#         \"y\": f\"PC2 ({pca_fly.explained_variance_ratio_[1]*100:.2f}%)\",\n",
    "#         \"z\": f\"PC3 ({pca_fly.explained_variance_ratio_[2]*100:.2f}%)\",\n",
    "#         \"color\": \"Cluster\"\n",
    "#     },\n",
    "#     title=\"3D PCA of intentions across all episodes\"\n",
    "# )\n",
    "\n",
    "# fig.update_traces(marker=dict(size=5, opacity=0.5))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(pca_embedded_fly[:, 0], pca_embedded_fly[:, 1], alpha=0.5)\n",
    "plt.title(\"Fly data in PCA space (own PCA)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(pca_embedded_rodent[:, 0], pca_embedded_rodent[:, 1], alpha=0.5, color=\"orange\")\n",
    "plt.title(\"Rodent data in PCA space (own PCA)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = np.vstack([activations_rodent, activations_fly])\n",
    "\n",
    "# Fit a single PCA on the combined dataset\n",
    "pca_shared = PCA(n_components=2, random_state=42)\n",
    "pca_shared.fit(combined_data)\n",
    "\n",
    "# Transform each set into the same 2D space\n",
    "fly_2d_shared = pca_shared.transform(activations_fly)\n",
    "rodent_2d_shared = pca_shared.transform(activations_rodent)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(fly_2d_shared[:, 0], fly_2d_shared[:, 1], \n",
    "            alpha=0.5, label=\"Fly\")\n",
    "plt.scatter(rodent_2d_shared[:, 0], rodent_2d_shared[:, 1], \n",
    "            alpha=0.5, label=\"Rodent\", color=\"orange\")\n",
    "plt.title(\"Fly vs. Rodent in a Shared PCA Space\")\n",
    "plt.xlabel(\"PC1 (shared)\")\n",
    "plt.ylabel(\"PC2 (shared)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_rodent = KMeans(n_clusters=5, random_state=42).fit(pca_embedded_rodent)\n",
    "rodent_labels = kmeans_rodent.labels_\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(pca_embedded_rodent[:, 0], pca_embedded_rodent[:, 1], \n",
    "            c=rodent_labels, cmap='tab10', alpha=0.6)\n",
    "plt.title(\"Rodent Clusters in PCA space\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n",
    "\n",
    "kmeans_fly = KMeans(n_clusters=5, random_state=42).fit(pca_embedded_fly)\n",
    "fly_labels = kmeans_fly.labels_\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(pca_embedded_fly[:, 0], pca_embedded_fly[:, 1], \n",
    "            c=fly_labels, cmap='tab10', alpha=0.6)\n",
    "plt.title(\"Fly Clusters in PCA space\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for clustering plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_intention_with_clusters(\n",
    "    frame_idx: int,\n",
    "    pca_projections: np.ndarray,\n",
    "    cluster_labels: np.ndarray,\n",
    "    var: np.ndarray,\n",
    "    clip_idx: int,\n",
    "    n_components: int,\n",
    "    terminated: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the PCA progression for the entire rollout, color-coded by clusters.\n",
    "    Highlight the current frame in some way.\n",
    "    Returns an RGB image (H x W x 3) as a numpy array, where the height matches \n",
    "    the MuJoCo frame (e.g., 480px).\n",
    "    \"\"\"\n",
    "    \n",
    "    #   4.8 inches * 100 dpi = 480 px\n",
    "    fig, ax = plt.subplots(figsize=(6.4, 4.8), dpi=100)\n",
    "\n",
    "    if n_components < 2:\n",
    "        raise ValueError(\"This code expects at least 2 PCA components to plot in 2D.\")\n",
    "\n",
    "    x = pca_projections[:, 0]\n",
    "    y = pca_projections[:, 1]\n",
    "\n",
    "    # entire trajectory, color-coded by cluster\n",
    "    sc = ax.scatter(\n",
    "        x, \n",
    "        y, \n",
    "        c=cluster_labels, \n",
    "        cmap=\"tab10\", \n",
    "        alpha=0.3,\n",
    "        s=20\n",
    "    )\n",
    "\n",
    "    # highlight the current frame in a larger circle\n",
    "    ax.scatter(\n",
    "        x[frame_idx], \n",
    "        y[frame_idx], \n",
    "        c=[cluster_labels[frame_idx]], \n",
    "        cmap=\"tab10\", \n",
    "        edgecolor=\"black\", \n",
    "        s=100, \n",
    "        alpha=1.0\n",
    "    )\n",
    "\n",
    "    title_str = f\"Clip {clip_idx} - Frame {frame_idx} - Cluster {cluster_labels[frame_idx]}\"\n",
    "    if terminated:\n",
    "        title_str = f\"Clip {clip_idx} - Final Frame - Cluster {cluster_labels[frame_idx]}\"\n",
    "    ax.set_title(title_str)\n",
    "    ax.set_xlabel(f\"PC1 ({var[0]*100:.2f}%)\")\n",
    "    ax.set_ylabel(f\"PC2 ({var[1]*100:.2f}%)\")\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.canvas.get_width_height()  # should be 640 x 480\n",
    "    plot_img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(height, width, 3)\n",
    "\n",
    "    plt.close(fig)\n",
    "    return plot_img\n",
    "\n",
    "def render_with_pca_progression_and_clusters(\n",
    "    rollout: dict, \n",
    "    pca_projections: np.ndarray, \n",
    "    cluster_labels: np.ndarray,\n",
    "    var: np.ndarray,\n",
    "    n_components: int = 2, \n",
    "    walker_name: str = \"rodent\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Render the MuJoCo frames side-by-side with a PCA+cluster progression graph\n",
    "    showing which cluster is active at each frame.\n",
    "    \"\"\"\n",
    "    # raw Mujoco frames (assume length T+1), then skip the first frame\n",
    "    frames_mujoco = render_from_saved_rollout(rollout, walker_name)[1:]  \n",
    "    # Now frames_mujoco has length T if your rollout is T steps\n",
    "\n",
    "    T = len(frames_mujoco)  \n",
    "    if T != len(pca_projections):\n",
    "        raise ValueError(f\"Mismatch: got {T} Mujoco frames vs {len(pca_projections)} PCA steps.\")\n",
    "\n",
    "    # parallel plotting\n",
    "    orig_backend = matplotlib.get_backend()\n",
    "    matplotlib.use(\"Agg\")  # headless for parallel figure creation\n",
    "\n",
    "    clip_idx = int(rollout[\"info\"][0][\"clip_idx\"])\n",
    "    episode_start = 0\n",
    "\n",
    "    # partial function to handle each time step's plot\n",
    "    worker = functools.partial(\n",
    "        plot_pca_intention_with_clusters,\n",
    "        pca_projections=pca_projections,\n",
    "        cluster_labels=cluster_labels,\n",
    "        clip_idx=clip_idx,\n",
    "        n_components=n_components,\n",
    "        var=var,\n",
    "    )\n",
    "\n",
    "    print(\"Rendering PCA + Cluster progression...\")\n",
    "\n",
    "    # create PCA+cluster frames in parallel for all timesteps\n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        frames_pca = pool.map(worker, range(T))\n",
    "\n",
    "    # concatenate frames side-by-side\n",
    "    concat_frames = []\n",
    "    print(\"Concatenating frames...\")\n",
    "    for idx in tqdm(range(T)):\n",
    "        # The shapes of frames_mujoco[idx] and frames_pca[idx] \n",
    "        # should now match in height, so hstack won't error.\n",
    "        concat = np.hstack([frames_mujoco[idx], frames_pca[idx]])\n",
    "        concat_frames.append(concat)\n",
    "\n",
    "    # terminated PCA frame at the end\n",
    "    reward_plot = plot_pca_intention_with_clusters(\n",
    "        frame_idx=T - 1,\n",
    "        pca_projections=pca_projections,\n",
    "        cluster_labels=cluster_labels,\n",
    "        clip_idx=clip_idx,\n",
    "        n_components=n_components,\n",
    "        terminated=True,\n",
    "        var=var,\n",
    "    )\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    matplotlib.use(orig_backend)\n",
    "\n",
    "    # short pause at the end (50 repeated frames)\n",
    "    final_frame = frames_mujoco[-1]\n",
    "    for _ in range(50):\n",
    "        concat_frames.append(np.hstack([final_frame, reward_plot]))\n",
    "\n",
    "    return concat_frames\n",
    "\n",
    "def global_local_pca_worker(\n",
    "    frame_idx: int,\n",
    "    pca_global: np.ndarray,\n",
    "    cluster_global: np.ndarray,\n",
    "    global_subset_indices: np.ndarray,\n",
    "    pca_local: np.ndarray,\n",
    "    cluster_local: np.ndarray,\n",
    "    T: int,\n",
    "    clip_idx: int,\n",
    "    var_lcoal: np.ndarray,\n",
    "    var_global: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The picklable worker function called by Pool.\n",
    "    \"\"\"\n",
    "    is_terminated = (frame_idx == T - 1)\n",
    "    return plot_global_and_local_pca_intention_with_clusters(\n",
    "        pca_global=pca_global,\n",
    "        cluster_global=cluster_global,\n",
    "        global_subset_indices=global_subset_indices,\n",
    "        pca_local=pca_local,\n",
    "        cluster_local=cluster_local,\n",
    "        frame_idx_local=frame_idx,\n",
    "        clip_idx=clip_idx,\n",
    "        var_lcoal=var_lcoal,\n",
    "        var_global=var_global,\n",
    "        terminated=is_terminated,\n",
    "    )\n",
    "\n",
    "def plot_global_and_local_pca_intention_with_clusters(\n",
    "    pca_global: np.ndarray,\n",
    "    cluster_global: np.ndarray, \n",
    "    global_subset_indices: np.ndarray, \n",
    "    pca_local: np.ndarray, \n",
    "    cluster_local: np.ndarray,\n",
    "    frame_idx_local: int,\n",
    "    clip_idx: int,\n",
    "    var_lcoal: np.ndarray,\n",
    "    var_global: np.ndarray,\n",
    "    terminated: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot side-by-side:\n",
    "    1) Global PCA (left subplot): entire dataset in gray, this clip in color, highlight current frame.\n",
    "    2) Local PCA (right subplot): just this clip, highlight current frame.\n",
    "    \n",
    "    Returns an RGB image (H x W x 3) as a numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # assume the local embedding is T points and we have T frames. frame_idx_local in [0..T).\n",
    "    T = len(pca_local)\n",
    "    if frame_idx_local >= T:\n",
    "        raise ValueError(f\"frame_idx_local={frame_idx_local} exceeds local clip length={T}.\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12.8, 4.8), dpi=100)\n",
    "    \n",
    "    all_x_g = pca_global[:, 0]\n",
    "    all_y_g = pca_global[:, 1]\n",
    "    \n",
    "    # light grey plot\n",
    "    ax1.scatter(all_x_g, all_y_g, color=\"lightgray\", alpha=0.5, s=10, label=\"All data (global)\")\n",
    "\n",
    "    # highlight just the points belonging to this clip\n",
    "    # pca_global_clip shape is (T, 2) if global_subset_indices has length T\n",
    "    pca_global_clip = pca_global[global_subset_indices]\n",
    "    cluster_global_clip = cluster_global[global_subset_indices]\n",
    "\n",
    "    x_clip_g = pca_global_clip[:, 0]\n",
    "    y_clip_g = pca_global_clip[:, 1]\n",
    "\n",
    "    sc = ax1.scatter(\n",
    "        x_clip_g,\n",
    "        y_clip_g,\n",
    "        c=cluster_global_clip,\n",
    "        cmap=\"tab10\",\n",
    "        alpha=0.7,\n",
    "        s=30,\n",
    "        label=f\"Clip {clip_idx}\"\n",
    "    )\n",
    "\n",
    "    # frame_idx_local corresponds to subset_indices[frame_idx_local] in the global space\n",
    "    current_global_idx = global_subset_indices[frame_idx_local]\n",
    "    cur_x_g = pca_global[current_global_idx, 0]\n",
    "    cur_y_g = pca_global[current_global_idx, 1]\n",
    "    cur_clust_g = cluster_global[current_global_idx]\n",
    "\n",
    "    ax1.scatter(\n",
    "        cur_x_g, \n",
    "        cur_y_g, \n",
    "        c=[cur_clust_g], \n",
    "        cmap=\"tab10\",\n",
    "        edgecolor=\"black\",\n",
    "        s=100,\n",
    "        alpha=1.0\n",
    "    )\n",
    "    ax1.set_title(f\"Global PCA (Clip {clip_idx})\")\n",
    "    ax1.set_xlabel(f\"PC1 (global) ({var_global[0]*100:.2f}%)\")\n",
    "    ax1.set_ylabel(f\"PC2 (global) ({var_global[1]*100:.2f}%)\")\n",
    "    \n",
    "\n",
    "    x_l = pca_local[:, 0]\n",
    "    y_l = pca_local[:, 1]\n",
    "    sc2 = ax2.scatter(\n",
    "        x_l, \n",
    "        y_l, \n",
    "        c=cluster_local, \n",
    "        cmap=\"tab10\",\n",
    "        alpha=0.7,\n",
    "        s=30,\n",
    "        label=f\"Clip {clip_idx} local\"\n",
    "    )\n",
    "\n",
    "    ax2.scatter(\n",
    "        x_l[frame_idx_local],\n",
    "        y_l[frame_idx_local],\n",
    "        c=[cluster_local[frame_idx_local]],\n",
    "        cmap=\"tab10\",\n",
    "        edgecolor=\"black\",\n",
    "        s=100,\n",
    "        alpha=1.0\n",
    "    )\n",
    "    local_title_str = f\"Local PCA: Clip {clip_idx}, Frame {frame_idx_local}\"\n",
    "    if terminated:\n",
    "        local_title_str += \" (terminated)\"\n",
    "    ax2.set_title(local_title_str)\n",
    "    ax2.set_xlabel(f\"PC1 (local) ({var_lcoal[0]*100:.2f}%)\")\n",
    "    ax2.set_ylabel(f\"PC2 (local) ({var_lcoal[1]*100:.2f}%)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.canvas.get_width_height()\n",
    "    img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(height, width, 3)\n",
    "    plt.close(fig)\n",
    "    return img\n",
    "\n",
    "\n",
    "def render_with_global_and_local_pca_progression(\n",
    "    rollout: dict,\n",
    "    walker_name: str,\n",
    "    pca_global: np.ndarray,\n",
    "    cluster_global: np.ndarray,\n",
    "    global_subset_indices: np.ndarray,\n",
    "    pca_local: np.ndarray,\n",
    "    cluster_local: np.ndarray,\n",
    "    var_lcoal: np.ndarray,\n",
    "    var_global: np.ndarray,\n",
    "):\n",
    "    \"\"\"\n",
    "    Render the MuJoCo frames side-by-side with a figure showing\n",
    "    BOTH global PCA + local PCA for each frame.\n",
    "    \"\"\"\n",
    "    \n",
    "    frames_mujoco = render_from_saved_rollout(rollout, walker_name)[1:]\n",
    "    T = len(frames_mujoco)\n",
    "    \n",
    "    if T != len(pca_local):\n",
    "        raise ValueError(f\"Mismatch: {T} MuJoCo frames vs {len(pca_local)} local PCA steps.\")\n",
    "    if T != len(global_subset_indices):\n",
    "        raise ValueError(f\"Mismatch: {T} frames vs {len(global_subset_indices)} global_subset_indices.\")\n",
    "\n",
    "    clip_idx = int(rollout[\"info\"][0][\"clip_idx\"])\n",
    "    orig_backend = matplotlib.get_backend()\n",
    "    matplotlib.use(\"Agg\")\n",
    "\n",
    "    worker_args = []\n",
    "    for frame_idx in range(T):\n",
    "        worker_args.append((\n",
    "            frame_idx,\n",
    "            pca_global,\n",
    "            cluster_global,\n",
    "            global_subset_indices,\n",
    "            pca_local,\n",
    "            cluster_local,\n",
    "            T,\n",
    "            clip_idx,\n",
    "            var_lcoal,\n",
    "            var_global,\n",
    "        ))\n",
    "    \n",
    "    print(\"Rendering PCA (global+local) progression...\")\n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        frames_pca = pool.starmap(global_local_pca_worker, worker_args)\n",
    "        \n",
    "    concat_frames = []\n",
    "    for idx in range(T):\n",
    "        concat_img = np.hstack([frames_mujoco[idx], frames_pca[idx]])\n",
    "        concat_frames.append(concat_img)\n",
    "\n",
    "    matplotlib.use(orig_backend)\n",
    "    return concat_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialized the PCA result to disk\n",
    "\n",
    "In this way, we can directly load the pca object to do the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize PCA components to a dictionary\n",
    "pca_data = {\n",
    "    \"components_\": pca_fly.components_.tolist(),\n",
    "    \"explained_variance_\": pca_fly.explained_variance_.tolist(),\n",
    "    \"explained_variance_ratio_\": pca_fly.explained_variance_ratio_.tolist(),\n",
    "    \"mean_\": pca_fly.mean_.tolist(),\n",
    "    \"n_components_\": pca_fly.n_components_,\n",
    "}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"pca_intention_fly.json\", \"w\") as f:\n",
    "    json.dump(pca_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the PCA object from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pca_intention_fly.json\", \"r\") as f:\n",
    "    loaded_pca_data = json.load(f)\n",
    "\n",
    "# Reconstruct the PCA object\n",
    "pca = PCA(n_components=loaded_pca_data[\"n_components_\"])\n",
    "pca.components_ = np.array(loaded_pca_data[\"components_\"])\n",
    "pca.explained_variance_ = np.array(loaded_pca_data[\"explained_variance_\"])\n",
    "pca.explained_variance_ratio_ = np.array(loaded_pca_data[\"explained_variance_ratio_\"])\n",
    "pca.mean_ = np.array(loaded_pca_data[\"mean_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This PCA laods in data from the fly, not the rodent, this is only for demonstrating, not actually using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA + Mujoco Rendering W/ Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id = 1\n",
    "directory = f\"/root/vast/kaiwen/track-mjx/rodent_rollout_info/\"\n",
    "with h5py.File(directory + f\"clip_{clip_id}.h5\", \"r\") as h5file:\n",
    "    rollout = load_from_h5py(h5file)\n",
    "    # directly get out the activations\n",
    "    act = get_aggregate_data(\"/activations\", ['intention'], clip_id, directory)\n",
    "\n",
    "len(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout['info'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout['info'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id = 2\n",
    "directory = f\"/root/vast/kaiwen/track-mjx/rodent_rollout_info/\"\n",
    "with h5py.File(directory + f\"clip_{clip_id}.h5\", \"r\") as h5file:\n",
    "    rollout = load_from_h5py(h5file)\n",
    "    # directly get out the activations\n",
    "    act = get_aggregate_data(\"/activations\", ['intention'], clip_id, directory)\n",
    "\n",
    "act = act[:599] # ref only have 600\n",
    "\n",
    "act = scaler.fit_transform(act)\n",
    "pca_fly = PCA()\n",
    "pca_fly.fit(act)\n",
    "pca_embedded = pca_fly.transform(act)\n",
    "kmeans = KMeans(n_clusters=4, random_state=42).fit(pca_embedded)\n",
    "frames = render_with_pca_progression_and_clusters(rollout=rollout, pca_projections=pca_embedded, cluster_labels=kmeans.labels_, n_components=2, walker_name=\"fly\", var=pca_fly.explained_variance_ratio_)\n",
    "display_video(frames, framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id = 0\n",
    "directory = f\"/root/vast/scott-yang/rodent_rollout_info/data/\"\n",
    "with h5py.File(directory + f\"clip_{clip_id}.h5\", \"r\") as h5file:\n",
    "    rollout = load_from_h5py(h5file)\n",
    "    # directly get out the activations\n",
    "    act = get_aggregate_data(\"/activations\", ['intention'], clip_id, directory)\n",
    "\n",
    "act = scaler.fit_transform(act)\n",
    "pca_rodent = PCA()\n",
    "pca_rodent.fit(act)\n",
    "pca_embedded = pca_rodent.transform(act)\n",
    "kmeans = KMeans(n_clusters=4, random_state=42).fit(pca_embedded)\n",
    "frames = render_with_pca_progression_and_clusters(rollout=rollout, pca_projections=pca_embedded, cluster_labels=kmeans.labels_, n_components=2, walker_name=\"rodent\", var=pca_rodent.explained_variance_ratio_)\n",
    "display_video(frames, framerate=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get global PCA plotting then mujoco rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id = 5\n",
    "clip_length = 599\n",
    "start = clip_id * clip_length \n",
    "end = start + clip_length\n",
    "global_subset_indices = np.arange(start, end)\n",
    "\n",
    "directory = f\"/root/vast/kaiwen/track-mjx/rodent_rollout_info/\"\n",
    "with h5py.File(directory + f\"clip_{clip_id}.h5\", \"r\") as h5file:\n",
    "    rollout = load_from_h5py(h5file)\n",
    "    act = get_aggregate_data(\"/activations\", ['intention'], clip_id, directory)\n",
    "\n",
    "act = act[:599] # ref only have 600\n",
    "act = scaler.fit_transform(act)\n",
    "activations_fly = scaler.fit_transform(activations_fly)\n",
    "\n",
    "pca_fly = PCA()\n",
    "pca_fly.fit(activations_fly)\n",
    "global_embedding = pca_fly.transform(activations_fly)\n",
    "global_labels = KMeans(n_clusters=4, random_state=42).fit(global_embedding).labels_\n",
    "\n",
    "pca_local = PCA()\n",
    "pca_local.fit(act)\n",
    "local_embedding = pca_local.transform(act)\n",
    "local_labels = KMeans(n_clusters=4, random_state=42).fit(local_embedding).labels_\n",
    "\n",
    "frames = render_with_global_and_local_pca_progression(\n",
    "    rollout=rollout,\n",
    "    walker_name=\"fly\",\n",
    "    pca_global=global_embedding, \n",
    "    cluster_global=global_labels,\n",
    "    global_subset_indices=global_subset_indices,\n",
    "    pca_local=local_embedding,\n",
    "    cluster_local=local_labels,\n",
    "    var_lcoal=pca_fly.explained_variance_ratio_,\n",
    "    var_global=pca_local.explained_variance_ratio_,\n",
    ")\n",
    "display_video(frames, framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id = 20\n",
    "clip_length = 599\n",
    "start = clip_id * clip_length \n",
    "end = start + clip_length\n",
    "global_subset_indices = np.arange(start, end)\n",
    "\n",
    "directory = f\"/root/vast/kaiwen/track-mjx/rodent_rollout_info/\"\n",
    "with h5py.File(directory + f\"clip_{clip_id}.h5\", \"r\") as h5file:\n",
    "    rollout = load_from_h5py(h5file)\n",
    "    act = get_aggregate_data(\"/activations\", ['intention'], clip_id, directory)\n",
    "\n",
    "act = act[:599] # ref only have 600\n",
    "act = scaler.fit_transform(act)\n",
    "activations_fly = scaler.fit_transform(activations_fly)\n",
    "\n",
    "pca_fly = PCA()\n",
    "pca_fly.fit(activations_fly)\n",
    "global_embedding = pca_fly.transform(activations_fly)\n",
    "global_labels = KMeans(n_clusters=4, random_state=42).fit(global_embedding).labels_\n",
    "\n",
    "pca_local = PCA()\n",
    "pca_local.fit(act)\n",
    "local_embedding = pca_local.transform(act)\n",
    "local_labels = KMeans(n_clusters=4, random_state=42).fit(local_embedding).labels_\n",
    "\n",
    "frames = render_with_global_and_local_pca_progression(\n",
    "    rollout=rollout,\n",
    "    walker_name=\"fly\",\n",
    "    pca_global=global_embedding, \n",
    "    cluster_global=global_labels,\n",
    "    global_subset_indices=global_subset_indices,\n",
    "    pca_local=local_embedding,\n",
    "    cluster_local=local_labels,\n",
    "    var_lcoal=pca_fly.explained_variance_ratio_,\n",
    "    var_global=pca_local.explained_variance_ratio_,\n",
    ")\n",
    "display_video(frames, framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id = 20\n",
    "clip_length = 499\n",
    "start = clip_id * clip_length \n",
    "end = start + clip_length\n",
    "global_subset_indices = np.arange(start, end)\n",
    "\n",
    "directory = f\"/root/vast/scott-yang/rodent_rollout_info/data/\"\n",
    "with h5py.File(directory + f\"clip_{clip_id}.h5\", \"r\") as h5file:\n",
    "    rollout = load_from_h5py(h5file)\n",
    "    act = get_aggregate_data(\"/activations\", ['intention'], clip_id, directory)\n",
    "\n",
    "act = scaler.fit_transform(act)\n",
    "activations_rodent = scaler.fit_transform(activations_rodent)\n",
    "\n",
    "pca_rodent = PCA()\n",
    "pca_rodent.fit(activations_rodent)\n",
    "global_embedding = pca_rodent.transform(activations_rodent)\n",
    "global_labels = KMeans(n_clusters=4, random_state=42).fit(global_embedding).labels_\n",
    "\n",
    "pca_local = PCA()\n",
    "pca_local.fit(act)\n",
    "local_embedding = pca_local.transform(act)\n",
    "local_labels = KMeans(n_clusters=4, random_state=42).fit(local_embedding).labels_\n",
    "\n",
    "frames = render_with_global_and_local_pca_progression(\n",
    "    rollout=rollout,\n",
    "    walker_name=\"rodent\",\n",
    "    pca_global=global_embedding, \n",
    "    cluster_global=global_labels,\n",
    "    global_subset_indices=global_subset_indices,\n",
    "    pca_local=local_embedding,\n",
    "    cluster_local=local_labels,\n",
    "    var_lcoal=pca_fly.explained_variance_ratio_,\n",
    "    var_global=pca_local.explained_variance_ratio_,\n",
    ")\n",
    "display_video(frames, framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id = 500\n",
    "clip_length = 499\n",
    "start = clip_id * clip_length \n",
    "end = start + clip_length\n",
    "global_subset_indices = np.arange(start, end)\n",
    "\n",
    "directory = f\"/root/vast/scott-yang/rodent_rollout_info/data/\"\n",
    "with h5py.File(directory + f\"clip_{clip_id}.h5\", \"r\") as h5file:\n",
    "    rollout = load_from_h5py(h5file)\n",
    "    act = get_aggregate_data(\"/activations\", ['intention'], clip_id, directory)\n",
    "\n",
    "act = scaler.fit_transform(act)\n",
    "activations_rodent = scaler.fit_transform(activations_rodent)\n",
    "\n",
    "pca_rodent = PCA()\n",
    "pca_rodent.fit(activations_rodent)\n",
    "global_embedding = pca_rodent.transform(activations_rodent)\n",
    "global_labels = KMeans(n_clusters=4, random_state=42).fit(global_embedding).labels_\n",
    "\n",
    "pca_local = PCA()\n",
    "pca_local.fit(act)\n",
    "local_embedding = pca_local.transform(act)\n",
    "local_labels = KMeans(n_clusters=4, random_state=42).fit(local_embedding).labels_\n",
    "\n",
    "frames = render_with_global_and_local_pca_progression(\n",
    "    rollout=rollout,\n",
    "    walker_name=\"rodent\",\n",
    "    pca_global=global_embedding, \n",
    "    cluster_global=global_labels,\n",
    "    global_subset_indices=global_subset_indices,\n",
    "    pca_local=local_embedding,\n",
    "    cluster_local=local_labels,\n",
    "    var_lcoal=pca_fly.explained_variance_ratio_,\n",
    "    var_global=pca_local.explained_variance_ratio_,\n",
    ")\n",
    "display_video(frames, framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id = 200\n",
    "clip_length = 499\n",
    "start = clip_id * clip_length \n",
    "end = start + clip_length\n",
    "global_subset_indices = np.arange(start, end)\n",
    "\n",
    "directory = f\"/root/vast/scott-yang/rodent_rollout_info/data/\"\n",
    "with h5py.File(directory + f\"clip_{clip_id}.h5\", \"r\") as h5file:\n",
    "    rollout = load_from_h5py(h5file)\n",
    "    act = get_aggregate_data(\"/activations\", ['intention'], clip_id, directory)\n",
    "\n",
    "act = scaler.fit_transform(act)\n",
    "activations_rodent = scaler.fit_transform(activations_rodent)\n",
    "\n",
    "pca_rodent = PCA()\n",
    "pca_rodent.fit(activations_rodent)\n",
    "global_embedding = pca_rodent.transform(activations_rodent)\n",
    "global_labels = KMeans(n_clusters=4, random_state=42).fit(global_embedding).labels_\n",
    "\n",
    "pca_local = PCA()\n",
    "pca_local.fit(act)\n",
    "local_embedding = pca_local.transform(act)\n",
    "local_labels = KMeans(n_clusters=4, random_state=42).fit(local_embedding).labels_\n",
    "\n",
    "frames = render_with_global_and_local_pca_progression(\n",
    "    rollout=rollout,\n",
    "    walker_name=\"rodent\",\n",
    "    pca_global=global_embedding, \n",
    "    cluster_global=global_labels,\n",
    "    global_subset_indices=global_subset_indices,\n",
    "    pca_local=local_embedding,\n",
    "    cluster_local=local_labels,\n",
    "    var_lcoal=pca_fly.explained_variance_ratio_,\n",
    "    var_global=pca_local.explained_variance_ratio_,\n",
    ")\n",
    "display_video(frames, framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video(frames, framerate=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering With Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/root/vast/scott-yang/vnl_ray/clips/all_snippets.h5\", \"r\") as h5file:\n",
    "    group = h5file[\"clip_0/walkers/walker_0\"]\n",
    "    if isinstance(group, h5py.Dataset):\n",
    "        print(group[()])  # Read dataset value\n",
    "    else:\n",
    "        print(group.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"/root/vast/scott-yang/vnl_ray/clips/all_snips.p\", \"rb\") as file:\n",
    "    all_snips = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def extract_clip_info(snippet_path: str):\n",
    "    \"\"\"\n",
    "    Extracts the behavior label and clip number from a snippet filename.\n",
    "    \n",
    "    Example: '././snippets_2_25_2021/snips/Walk_145.p' -> ('Walk', 145)\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(snippet_path)  # e.g. 'Walk_145.p'\n",
    "    name, _ = os.path.splitext(filename)       # Remove '.p', e.g. 'Walk_145'\n",
    "\n",
    "    match = re.match(r\"([a-zA-Z]+)_(\\d+)\", name)  # Match 'Behavior_ClipNumber'\n",
    "    if match:\n",
    "        behavior = match.group(1)  # Extracts 'Walk', 'Rear', etc.\n",
    "        clip_number = int(match.group(2))  # Extracts '145'\n",
    "        return behavior, clip_number\n",
    "    else:\n",
    "        return None, None  # Handle unexpected filenames\n",
    "\n",
    "\n",
    "\n",
    "clip_info = [extract_clip_info(path) for path in all_snips[\"snips_order\"]]\n",
    "print(clip_info)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/root/vast/scott-yang/rodent_rollout_info/data/\"\n",
    "\n",
    "def load_clip_activations(clip_id):\n",
    "    \"\"\"\n",
    "    Loads activation data for a specific clip.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(directory, f\"clip_{clip_id}.h5\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: Clip {clip_id} not found!\")\n",
    "        return None\n",
    "    \n",
    "    with h5py.File(file_path, \"r\") as h5file:\n",
    "        act = get_aggregate_data(\"/activations\", ['intention'], clip_id, directory)  # shape (T, D)\n",
    "    return act\n",
    "\n",
    "# Load activations and labels for all snippets\n",
    "all_labels = []\n",
    "all_clip_ids = []\n",
    "\n",
    "for path in all_snips[\"snips_order\"]:\n",
    "    behavior, clip_id = extract_clip_info(path)\n",
    "    all_labels.append(behavior)\n",
    "    all_clip_ids.append(clip_id)\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_clip_ids = np.array(all_clip_ids)\n",
    "\n",
    "work_rodent = functools.partial(get_aggregate_data, \"/activations\", ['intention'], path=f\"/root/vast/scott-yang/rodent_rollout_info/data/\")\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    activations_rodent = list(tqdm(pool.imap(work_rodent, range(842)), total=842))\n",
    "\n",
    "activations_rodent = np.vstack(activations_rodent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_rodent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the number of clips matches expectations\n",
    "num_clips = len(all_clip_ids)  # Should be around 842 clips\n",
    "frames_per_clip = 499\n",
    "\n",
    "# Expand behavior labels to match frame-level activations\n",
    "expanded_labels = np.repeat(all_labels, frames_per_clip)\n",
    "expanded_clip_ids = np.repeat(all_clip_ids, frames_per_clip)\n",
    "\n",
    "# Ensure total matches 420,158 frames\n",
    "assert len(expanded_labels) == activations_rodent.shape[0]\n",
    "assert len(expanded_clip_ids) == activations_rodent.shape[0]\n",
    "\n",
    "print(f\"Expanded Labels Shape: {expanded_labels.shape}\")\n",
    "print(f\"Expanded Clip IDs Shape: {expanded_clip_ids.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(activations_rodent)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "var_explained = pca.explained_variance_ratio_ * 100\n",
    "print(f\"Explained variance: PC1 = {var_explained[0]:.2f}%, PC2 = {var_explained[1]:.2f}%\")\n",
    "\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "cluster_ids = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Compute majority behavior for each cluster\n",
    "cluster_to_behavior = {i: [] for i in range(k)}\n",
    "for i, cluster in enumerate(cluster_ids):\n",
    "    cluster_to_behavior[cluster].append(expanded_labels[i]) \n",
    "\n",
    "cluster_majority_behavior = {}\n",
    "for cluster, behaviors in cluster_to_behavior.items():\n",
    "    # Get most frequent behavior\n",
    "    most_common_behavior = Counter(behaviors).most_common(1)[0][0]\n",
    "    cluster_majority_behavior[cluster] = most_common_behavior\n",
    "    print(f\"Cluster {cluster} → Assigned Behavior: {most_common_behavior}\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=cluster_ids, palette=\"tab10\", alpha=0.7)\n",
    "plt.title(\"PCA Projection of Rodent Activations (K-Means Clustering)\")\n",
    "plt.xlabel(f\"PC1 ({var_explained[0]:.2f}%)\")\n",
    "plt.ylabel(f\"PC2 ({var_explained[1]:.2f}%)\")\n",
    "for cluster, behavior in cluster_majority_behavior.items():\n",
    "    cluster_center = np.mean(X_pca[cluster_ids == cluster], axis=0)\n",
    "    plt.text(cluster_center[0], cluster_center[1], behavior, fontsize=10, ha='center', va='center',\n",
    "             bbox=dict(facecolor='white', alpha=0.6, edgecolor='black'))\n",
    "\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activations Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "work_fly = functools.partial(get_aggregate_data, \"/activations\", ['decoder', 'layer_1'], path=f\"/root/vast/kaiwen/track-mjx/rodent_rollout_info\")\n",
    "work_rodent = functools.partial(get_aggregate_data, \"/activations\", ['decoder', 'layer_1'], path=f\"/root/vast/scott-yang/rodent_rollout_info/data/\")\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    activations_fly = list(tqdm(pool.imap(work_fly, range(499)), total=499))\n",
    "    activations_rodent = list(tqdm(pool.imap(work_rodent, range(842)), total=842))\n",
    "\n",
    "activations_fly = np.vstack(activations_fly)\n",
    "activations_rodent = np.vstack(activations_rodent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "activations_rodent = scaler.fit_transform(activations_rodent)\n",
    "activations_fly = scaler.fit_transform(activations_fly)\n",
    "\n",
    "pca_rodent = PCA()\n",
    "\n",
    "pca_rodent = pca_rodent.fit(activations_rodent)\n",
    "print(np.cumsum(pca_rodent.explained_variance_ratio_[:10]))\n",
    "pca_embedded_rodent = pca_rodent.transform(activations_rodent)\n",
    "\n",
    "pca_fly = PCA()\n",
    "\n",
    "pca_fly = pca_fly.fit(activations_fly)\n",
    "print(np.cumsum(pca_fly.explained_variance_ratio_[:10]))\n",
    "pca_embedded_fly = pca_fly.transform(activations_fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_rodent = KMeans(n_clusters=5, random_state=42).fit(pca_embedded_rodent)\n",
    "rodent_labels = kmeans_rodent.labels_\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(pca_embedded_rodent[:, 0], pca_embedded_rodent[:, 1], \n",
    "            c=rodent_labels, cmap='tab10', alpha=0.6)\n",
    "plt.title(\"Rodent Clusters in PCA space\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n",
    "\n",
    "kmeans_fly = KMeans(n_clusters=5, random_state=42).fit(pca_embedded_fly)\n",
    "fly_labels = kmeans_fly.labels_\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(pca_embedded_fly[:, 0], pca_embedded_fly[:, 1], \n",
    "            c=fly_labels, cmap='tab10', alpha=0.6)\n",
    "plt.title(\"Fly Clusters in PCA space\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_fly = PCA(n_components=3)\n",
    "pca_embedded_fly = pca_fly.fit_transform(activations_fly) \n",
    "\n",
    "k = 6\n",
    "kmeans_fly = KMeans(n_clusters=k, random_state=42).fit(pca_embedded_fly)\n",
    "fly_labels = kmeans_fly.labels_\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "N = pca_embedded_fly.shape[0]\n",
    "c_values = np.arange(N)\n",
    "\n",
    "sc = ax.scatter(\n",
    "    pca_embedded_fly[:, 0],\n",
    "    pca_embedded_fly[:, 1],\n",
    "    pca_embedded_fly[:, 2],\n",
    "    c=fly_labels,\n",
    "    cmap=\"tab20\",\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "cb = plt.colorbar(sc, ax=ax, shrink=0.6)\n",
    "cb.set_label(\"Sample Index\")\n",
    "\n",
    "ax.set_xlabel(f\"PC1 ({pca_fly.explained_variance_ratio_[0]*100:.2f}%)\")\n",
    "ax.set_ylabel(f\"PC2 ({pca_fly.explained_variance_ratio_[1]*100:.2f}%)\")\n",
    "ax.set_zlabel(f\"PC3 ({pca_fly.explained_variance_ratio_[2]*100:.2f}%)\")\n",
    "\n",
    "ax.set_title(\"3D PCA of intentions across all episodes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_rodent = PCA(n_components=3)\n",
    "pca_embedded_fly = pca_rodent.fit_transform(activations_rodent) \n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "N = pca_embedded_fly.shape[0]\n",
    "c_values = np.arange(N)\n",
    "\n",
    "sc = ax.scatter(\n",
    "    pca_embedded_fly[:, 0],\n",
    "    pca_embedded_fly[:, 1],\n",
    "    pca_embedded_fly[:, 2],\n",
    "    c=c_values,\n",
    "    cmap=\"tab20\",\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "cb = plt.colorbar(sc, ax=ax, shrink=0.6)\n",
    "cb.set_label(\"Sample Index\")\n",
    "\n",
    "ax.set_xlabel(f\"PC1 ({pca_rodent.explained_variance_ratio_[0]*100:.2f}%)\")\n",
    "ax.set_ylabel(f\"PC2 ({pca_rodent.explained_variance_ratio_[1]*100:.2f}%)\")\n",
    "ax.set_zlabel(f\"PC3 ({pca_rodent.explained_variance_ratio_[2]*100:.2f}%)\")\n",
    "\n",
    "ax.set_title(\"3D PCA of intentions across all episodes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(activations_rodent)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "var_explained = pca.explained_variance_ratio_ * 100\n",
    "print(f\"Explained variance: PC1 = {var_explained[0]:.2f}%, PC2 = {var_explained[1]:.2f}%\")\n",
    "\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "cluster_ids = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Compute majority behavior for each cluster\n",
    "cluster_to_behavior = {i: [] for i in range(k)}\n",
    "for i, cluster in enumerate(cluster_ids):\n",
    "    cluster_to_behavior[cluster].append(expanded_labels[i]) \n",
    "\n",
    "cluster_majority_behavior = {}\n",
    "for cluster, behaviors in cluster_to_behavior.items():\n",
    "    # Get most frequent behavior\n",
    "    most_common_behavior = Counter(behaviors).most_common(1)[0][0]\n",
    "    cluster_majority_behavior[cluster] = most_common_behavior\n",
    "    print(f\"Cluster {cluster} → Assigned Behavior: {most_common_behavior}\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=cluster_ids, palette=\"tab10\", alpha=0.7)\n",
    "plt.title(\"PCA Projection of Rodent Activations (K-Means Clustering)\")\n",
    "plt.xlabel(f\"PC1 ({var_explained[0]:.2f}%)\")\n",
    "plt.ylabel(f\"PC2 ({var_explained[1]:.2f}%)\")\n",
    "for cluster, behavior in cluster_majority_behavior.items():\n",
    "    cluster_center = np.mean(X_pca[cluster_ids == cluster], axis=0)\n",
    "    plt.text(cluster_center[0], cluster_center[1], behavior, fontsize=10, ha='center', va='center',\n",
    "             bbox=dict(facecolor='white', alpha=0.6, edgecolor='black'))\n",
    "\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [['encoder','layer_0'], ['encoder','layer_1'], ['decoder','layer_0'], ['decoder','layer_1']]\n",
    "\n",
    "fly_activations = {}\n",
    "rodent_activations = {}\n",
    "\n",
    "work_fly = {tuple(layer): functools.partial(get_aggregate_data, \"/activations\", layer,\n",
    "                                            path=\"/root/vast/kaiwen/track-mjx/rodent_rollout_info\") for layer in layers}\n",
    "work_rodent = {tuple(layer): functools.partial(get_aggregate_data, \"/activations\", layer,\n",
    "                                               path=\"/root/vast/scott-yang/rodent_rollout_info/data/\") for layer in layers}\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    for layer in layers:\n",
    "        layer_key = tuple(layer)  # Convert list to tuple to use as a dictionary key\n",
    "        activations_fly = list(tqdm(pool.imap(work_fly[layer_key], range(499)), total=499))\n",
    "        activations_rodent = list(tqdm(pool.imap(work_rodent[layer_key], range(842)), total=842))\n",
    "        fly_activations[layer_key] = np.vstack(activations_fly)\n",
    "        rodent_activations[layer_key] = np.vstack(activations_rodent)\n",
    "\n",
    "def process_and_plot_3d(activations, title, ax):\n",
    "    \"\"\"Performs PCA and K-Means clustering, then visualizes in 3D.\"\"\"\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_embedded = pca.fit_transform(activations)\n",
    "\n",
    "    k = 3\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42).fit(pca_embedded)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    sc = ax.scatter(\n",
    "        pca_embedded[:, 0], pca_embedded[:, 1], pca_embedded[:, 2],\n",
    "        c=labels, cmap=\"tab20\", alpha=0.5\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)\")\n",
    "    ax.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)\")\n",
    "    ax.set_zlabel(f\"PC3 ({pca.explained_variance_ratio_[2]*100:.2f}%)\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "def process_and_plot_2d(activations, title, ax):\n",
    "    \"\"\"Performs PCA and K-Means clustering, then visualizes in 2D.\"\"\"\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_embedded = pca.fit_transform(activations)\n",
    "\n",
    "    k = 3\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42).fit(pca_embedded)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    sc = ax.scatter(\n",
    "        pca_embedded[:, 0], pca_embedded[:, 1], c=labels, cmap=\"tab10\", alpha=0.6\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)\")\n",
    "    ax.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)\")\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    process_and_plot_2d(fly_activations[tuple(layer)], f\"Fly - {layer[0]} {layer[1]}\", axes[0, i])\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    process_and_plot_2d(rodent_activations[tuple(layer)], f\"Rodent - {layer[0]} {layer[1]}\", axes[1, i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(22, 10), subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    process_and_plot_3d(fly_activations[tuple(layer)], f\"Fly - {layer[0]} {layer[1]}\", axes[0, i])\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    process_and_plot_3d(rodent_activations[tuple(layer)], f\"Rodent - {layer[0]} {layer[1]}\", axes[1, i])\n",
    "\n",
    "fig.subplots_adjust(left=0.05, right=0.95, top=0.90, bottom=0.10, wspace=0.35, hspace=0.40)\n",
    "\n",
    "# Rotate 3D plots and adjust font sizes for better readability\n",
    "for ax in axes.flat:\n",
    "    ax.view_init(elev=25, azim=40)  # Adjust camera angles\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)  # Smaller tick labels\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=10, labelpad=12)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=10, labelpad=12)\n",
    "    ax.set_zlabel(ax.get_zlabel(), fontsize=10, labelpad=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(22, 10), subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    process_and_plot_3d(fly_activations[tuple(layer)], f\"Fly - {layer[0]} {layer[1]}\", axes[0, i])\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    process_and_plot_3d(rodent_activations[tuple(layer)], f\"Rodent - {layer[0]} {layer[1]}\", axes[1, i])\n",
    "\n",
    "fig.subplots_adjust(left=0.05, right=0.95, top=0.90, bottom=0.10, wspace=0.35, hspace=0.40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEAP Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "work_fly = functools.partial(get_aggregate_data, \"/qposes_rollout\", [], path=f\"/root/vast/kaiwen/track-mjx/rodent_rollout_info\")\n",
    "work_rodent = functools.partial(get_aggregate_data, \"/qposes_rollout\", [], path=f\"/root/vast/scott-yang/rodent_rollout_info/data/\")\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    qpos_fly = list(tqdm(pool.imap(work_fly, range(30)), total=30))\n",
    "    qpos_rodent = list(tqdm(pool.imap(work_rodent, range(842)), total=842))\n",
    "\n",
    "qpos_fly = np.vstack(qpos_fly)\n",
    "qpos_rodent = np.vstack(qpos_rodent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qpos_fly.shape, qpos_rodent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco\n",
    "\n",
    "pair_render_xml_path = \"/root/vast/kaiwen/track-mjx/track_mjx/environment/walker/assets/fruitfly/fruitfly_force_pair.xml\"\n",
    "mj_model = mujoco.MjModel.from_xml_path(pair_render_xml_path)\n",
    "\n",
    "for i in range(73):\n",
    "    print(f\"Index {i}: {mj_model.joint(i).name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_render_xml_path = \"/root/vast/scott-yang/track-mjx/track_mjx/environment/walker/assets/rodent/rodent_ghostpair_scale080.xml\"\n",
    "mj_model = mujoco.MjModel.from_xml_path(pair_render_xml_path)\n",
    "\n",
    "for i in range(73):\n",
    "    print(f\"Index {i}: {mj_model.joint(i).name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clips = qpos_fly.shape[0] // 599\n",
    "print(f\"Total clips: {num_clips}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def compute_forward_velocity(qposes, dt):\n",
    "    \"\"\"Computes forward velocity from qposes by differentiating COM position.\"\"\"\n",
    "    com_positions = qposes[:, 0]  # Assuming x-position of COM is at index 0\n",
    "    return np.gradient(com_positions, dt)\n",
    "\n",
    "def compute_leg_phases(qposes, leg_indices, threshold=0.02, smooth_sigma=1):\n",
    "    \"\"\"\n",
    "    Determines swing (1) or stance (0) phases for each leg tip.\n",
    "    Uses correct leg tip height indices extracted from MuJoCo model.\n",
    "    \"\"\"\n",
    "    leg_heights = qposes[:, leg_indices]\n",
    "    raw_leg_phases = (leg_heights > threshold).astype(int)\n",
    "    smoothed_leg_phases = gaussian_filter1d(raw_leg_phases, sigma=smooth_sigma, axis=0)\n",
    "    return (smoothed_leg_phases > 0.5).astype(int)  # Re-binarize\n",
    "\n",
    "def plot_gait_analysis(qposes, leg_indices, leg_labels, dt, clip_id, timesteps_per_clip, color, title):\n",
    "    \"\"\"Plots Forward Velocity and Leg Phases for a given dataset.\"\"\"\n",
    "    start_idx = clip_id * timesteps_per_clip\n",
    "    end_idx = start_idx + timesteps_per_clip\n",
    "    qposes_clip = qposes[start_idx:end_idx, :]\n",
    "\n",
    "    # Compute velocity and leg phases\n",
    "    forward_velocity = compute_forward_velocity(qposes_clip, dt)\n",
    "    leg_phases = compute_leg_phases(qposes_clip, leg_indices)\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(7, 5), gridspec_kw={'height_ratios': [1, 3]})\n",
    "    time_axis = np.linspace(0, timesteps_per_clip * dt, timesteps_per_clip)\n",
    "\n",
    "    # Top: Forward Velocity\n",
    "    axes[0].plot(time_axis, forward_velocity, color=color, linewidth=1)\n",
    "    axes[0].set_ylabel(\"Forward velocity (mm/s)\")\n",
    "    axes[0].set_xticks([])\n",
    "    axes[0].set_xlim(0, time_axis[-1])\n",
    "\n",
    "    # Bottom: Leg Phases (Swing/Stance)\n",
    "    axes[1].imshow(leg_phases.T, cmap=\"gray_r\", aspect=\"auto\", interpolation=\"nearest\")\n",
    "    axes[1].set_yticks(np.arange(len(leg_labels)))\n",
    "    axes[1].set_yticklabels(leg_labels)\n",
    "    axes[1].set_xlabel(\"Time (s)\")\n",
    "    axes[1].set_xticks(np.linspace(0, timesteps_per_clip - 1, 6))\n",
    "    axes[1].set_xticklabels(np.round(np.linspace(0, timesteps_per_clip * dt, 6), 2))\n",
    "\n",
    "    # Swing/Stance Legend\n",
    "    legend_patches = [plt.Line2D([0], [0], color=\"black\", lw=4, label=\"Swing\"),\n",
    "                      plt.Line2D([0], [0], color=\"white\", lw=4, label=\"Stance\")]\n",
    "    axes[1].legend(handles=legend_patches, loc=\"upper right\", frameon=True, edgecolor=\"black\")\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Fly Configuration ---\n",
    "fly_leg_indices = [6, 12, 18, 24, 30, 36]\n",
    "fly_leg_labels = [\"Front Leg (T1) Left\", \"Front Leg (T1) Right\",\n",
    "                  \"Middle Leg (T2) Left\", \"Middle Leg (T2) Right\",\n",
    "                  \"Hind Leg (T3) Left\", \"Hind Leg (T3) Right\"]\n",
    "plot_gait_analysis(qpos_fly, fly_leg_indices, fly_leg_labels, dt=1/500, clip_id=0, timesteps_per_clip=599, color='blue', title=\"Fly - Gait Analysis\")\n",
    "\n",
    "# --- Rodent Configuration ---\n",
    "rodent_leg_indices = [12, 18, 59, 67]\n",
    "rodent_leg_labels = [\"Hind Left (Toe)\", \"Hind Right (Toe)\", \"Fore Left (Finger)\", \"Fore Right (Finger)\"]\n",
    "plot_gait_analysis(qpos_rodent, rodent_leg_indices, rodent_leg_labels, dt=1/50, clip_id=0, timesteps_per_clip=250, color='red', title=\"Rodent - Gait Analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forward_velocity(qposes, dt, smooth_sigma=2):\n",
    "    \"\"\"Computes and smooths forward velocity using central differencing.\"\"\"\n",
    "    \n",
    "    com_positions = qposes[:, 0]\n",
    "    raw_velocities = (com_positions[2:] - com_positions[:-2]) / (2 * dt)  # Central difference\n",
    "    raw_velocities = np.insert(raw_velocities, 0, raw_velocities[0])  # Pad first value\n",
    "    raw_velocities = np.append(raw_velocities, raw_velocities[-1])  # Pad last value\n",
    "    return gaussian_filter1d(raw_velocities, sigma=smooth_sigma)\n",
    "\n",
    "def compute_leg_phases(qposes, leg_indices, threshold=0.05):\n",
    "    \"\"\"Determines swing (1) or stance (0) phases for each leg tip.\"\"\"\n",
    "    \n",
    "    leg_heights = qposes[:, leg_indices]\n",
    "    raw_leg_phases = (leg_heights > threshold).astype(int) # > is swing, <= is stance\n",
    "    return (raw_leg_phases > 0.5).astype(int)  # Re-binarize\n",
    "\n",
    "def plot_gait_analysis_horizontal(qposes, leg_indices, leg_labels, dt, clip_start, num_clips, timesteps_per_clip, color, title_prefix):\n",
    "    \"\"\"Plots multiple clips side-by-side in a horizontal layout but keeps each as a distinct figure.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_clips, figsize=(5 * num_clips, 6), gridspec_kw={'height_ratios': [1, 3]})\n",
    "\n",
    "    for i in range(num_clips):\n",
    "        clip_id = clip_start + i\n",
    "        start_idx = clip_id * timesteps_per_clip\n",
    "        end_idx = start_idx + timesteps_per_clip\n",
    "        qposes_clip = qposes[start_idx:end_idx, :]\n",
    "\n",
    "        # Compute velocity and leg phases\n",
    "        forward_velocity = compute_forward_velocity(qposes_clip, dt)\n",
    "        leg_phases = compute_leg_phases(qposes_clip, leg_indices)\n",
    "\n",
    "        # Time axis in seconds\n",
    "        time_axis = np.linspace(0, timesteps_per_clip * dt, timesteps_per_clip)\n",
    "\n",
    "        # --- Top Row: Forward Velocity ---\n",
    "        axes[0, i].plot(time_axis, forward_velocity, color=color, linewidth=1)\n",
    "        axes[0, i].set_ylabel(\"Velocity (mm/s)\")\n",
    "        axes[0, i].set_xticks([])\n",
    "        axes[0, i].set_xlim(0, time_axis[-1])\n",
    "        axes[0, i].set_title(f\"{title_prefix} - Clip {clip_id}\")\n",
    "\n",
    "        # --- Bottom Row: Leg Phases ---\n",
    "        im = axes[1, i].imshow(leg_phases.T, cmap=\"gray_r\", aspect=\"auto\", interpolation=\"nearest\")\n",
    "        axes[1, i].set_yticks(np.arange(len(leg_labels)))\n",
    "        axes[1, i].set_yticklabels(leg_labels)\n",
    "        axes[1, i].set_xlabel(\"Time (s)\")\n",
    "        axes[1, i].set_xticks(np.linspace(0, timesteps_per_clip - 1, 6))\n",
    "        axes[1, i].set_xticklabels(np.round(np.linspace(0, timesteps_per_clip * dt, 6), 2))\n",
    "\n",
    "        # Swing/Stance Legend (only add on last one for space)\n",
    "        if i == num_clips - 1:\n",
    "            legend_patches = [plt.Line2D([0], [0], color=\"black\", lw=4, label=\"Swing\"),\n",
    "                              plt.Line2D([0], [0], color=\"white\", lw=4, label=\"Stance\")]\n",
    "            axes[1, i].legend(handles=legend_patches, loc=\"upper right\", frameon=True, edgecolor=\"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Fly Configuration ---\n",
    "fly_leg_indices = [6, 12, 18, 24, 30, 36]\n",
    "fly_leg_labels = [\"Front Leg (T1) Left\", \"Front Leg (T1) Right\",\n",
    "                  \"Middle Leg (T2) Left\", \"Middle Leg (T2) Right\",\n",
    "                  \"Hind Leg (T3) Left\", \"Hind Leg (T3) Right\"]\n",
    "plot_gait_analysis_horizontal(qpos_fly, fly_leg_indices, fly_leg_labels, dt=1/500, \n",
    "                              clip_start=0, num_clips=3, timesteps_per_clip=599, \n",
    "                              color='blue', title_prefix=\"Fly - Gait Analysis\")\n",
    "\n",
    "# --- Rodent Configuration ---\n",
    "rodent_leg_indices = [12, 18, 59, 67]\n",
    "rodent_leg_labels = [\"Hind Left (Toe)\", \"Hind Right (Toe)\", \"Fore Left (Finger)\", \"Fore Right (Finger)\"]\n",
    "plot_gait_analysis_horizontal(qpos_rodent, rodent_leg_indices, rodent_leg_labels, dt=1/50, \n",
    "                              clip_start=0, num_clips=3, timesteps_per_clip=250, \n",
    "                              color='red', title_prefix=\"Rodent - Gait Analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_leg_tip_heights(qposes, leg_indices, labels, dt, smooth_sigma=2, title=\"Leg Tip Heights Over Time\"):\n",
    "    \"\"\"\n",
    "    Plots the leg tip heights (Z-coordinates) over time.\n",
    "    - qposes: (T, D) array of joint positions.\n",
    "    - leg_indices: List of indices corresponding to the leg tip Z-coordinates.\n",
    "    - labels: List of labels for each leg.\n",
    "    - dt: Timestep for converting frames to time.\n",
    "    - smooth_sigma: Smoothing parameter for better visualization.\n",
    "    - title: Title of the plot.\n",
    "    \"\"\"\n",
    "    # Extract leg tip heights\n",
    "    leg_tips_z = qposes[:, leg_indices]\n",
    "\n",
    "    # Apply smoothing per leg\n",
    "    smoothed_leg_tips = np.array([gaussian_filter1d(leg_tips_z[:, i], sigma=smooth_sigma) for i in range(len(leg_indices))]).T\n",
    "\n",
    "    # Time axis in seconds\n",
    "    time_axis = np.arange(qposes.shape[0]) * dt\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i, label in enumerate(labels):\n",
    "        plt.plot(time_axis, smoothed_leg_tips[:, i], label=label, linewidth=1.5)\n",
    "\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Height (Z-coordinate)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# --- Fly Setup ---\n",
    "fly_leg_indices = [6, 12, 18, 24, 30, 36]  # Z-coordinates for Fly leg tips\n",
    "fly_leg_labels = [\"Front Leg (T1) Left\", \"Front Leg (T1) Right\",\n",
    "                  \"Middle Leg (T2) Left\", \"Middle Leg (T2) Right\",\n",
    "                  \"Hind Leg (T3) Left\", \"Hind Leg (T3) Right\"]\n",
    "\n",
    "# Select Fly Clip\n",
    "clip_id_fly = 0\n",
    "timesteps_per_clip_fly = 499\n",
    "start_idx_fly = clip_id_fly * timesteps_per_clip_fly\n",
    "end_idx_fly = start_idx_fly + timesteps_per_clip_fly\n",
    "qposes_fly_clip = qpos_fly[start_idx_fly:end_idx_fly, :]\n",
    "\n",
    "plot_leg_tip_heights(qposes_fly_clip, fly_leg_indices, fly_leg_labels, dt=1/500, title=\"Fly - Leg Tip Heights Over Time\")\n",
    "\n",
    "# --- Rodent Setup ---\n",
    "rodent_leg_indices = [12, 18, 59, 67]  # Z-coordinates for Rodent foot & hand tips\n",
    "rodent_leg_labels = [\"Hind Left (Toe)\", \"Hind Right (Toe)\",\n",
    "                     \"Fore Left (Finger)\", \"Fore Right (Finger)\"]\n",
    "\n",
    "# Select Rodent Clip\n",
    "clip_id_rodent = 0\n",
    "timesteps_per_clip_rodent = 250\n",
    "start_idx_rodent = clip_id_rodent * timesteps_per_clip_rodent\n",
    "end_idx_rodent = start_idx_rodent + timesteps_per_clip_rodent\n",
    "qposes_rodent_clip = qpos_rodent[start_idx_rodent:end_idx_rodent, :]\n",
    "\n",
    "plot_leg_tip_heights(qposes_rodent_clip, rodent_leg_indices, rodent_leg_labels, dt=1/50, title=\"Rodent - Leg Tip Heights Over Time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track_mjx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
