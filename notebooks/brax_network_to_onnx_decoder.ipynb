{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JaX Flax --> ONNX\n",
    "\n",
    "This notebook converts brax MLP networks to an ONNX checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "import jax\n",
    "\n",
    "# Enable persistent compilation cache.\n",
    "jax.config.update(\"jax_compilation_cache_dir\", \"/tmp/jax_cache\")\n",
    "jax.config.update(\"jax_persistent_cache_min_entry_size_bytes\", -1)\n",
    "jax.config.update(\"jax_persistent_cache_min_compile_time_secs\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "from mujoco_playground.config import locomotion_params, manipulation_params\n",
    "from mujoco_playground import locomotion, manipulation\n",
    "import functools\n",
    "import pickle\n",
    "import jax.numpy as jp\n",
    "import jax\n",
    "import tf2onnx\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import onnxruntime as rt\n",
    "from brax.training.acme import running_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from track_mjx.environment.walker import rodent\n",
    "from track_mjx.agent import checkpointing\n",
    "from track_mjx.agent.intention_network import Decoder\n",
    "from track_mjx.analysis.rollout import create_environment\n",
    "from track_mjx.environment.wrappers import EvalClipResetWrapper\n",
    "from track_mjx.analysis.render import render_from_saved_rollout, display_video\n",
    "from track_mjx.analysis.utils import save_to_h5py, load_from_h5py\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from brax.training import distribution\n",
    "from brax.training.acme import running_statistics\n",
    "from pathlib import Path\n",
    "\n",
    "# replace with your checkpoint path\n",
    "ckpt_path = \"/root/vast/scott-yang/track-mjx/model_checkpoints/250306_194809\"\n",
    "# Load config from checkpoint\n",
    "ckpt = checkpointing.load_checkpoint_for_eval(ckpt_path)\n",
    "\n",
    "cfg = ckpt[\"cfg\"]\n",
    "\n",
    "# make some changes to the config\n",
    "# replace with absolute path to your data\n",
    "# -- your notebook may not have access to the same relative path\n",
    "cfg.data_path = \"/root/vast/scott-yang/track-mjx/data/transform_snips.h5\"\n",
    "cfg.train_setup.checkpoint_to_restore = ckpt_path\n",
    "\n",
    "# NOTE: To use accelerated JAX.JIT, only run the following code only once.\n",
    "# If you re-run, you will triggers recompilations\n",
    "\n",
    "env = create_environment(cfg)\n",
    "\n",
    "# env_name = \"BerkeleyHumanoidJoystickFlatTerrain\"\n",
    "# # ppo_params = locomotion_params.brax_ppo_config(env_name)\n",
    "# ppo_params = locomotion_params.brax_ppo_config(env_name)z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_size = env.observation_size\n",
    "act_size = env.action_size\n",
    "print(obs_size, act_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg[\"network_config\"][\"reference_obs_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the abstract decoder\n",
    "network_config = cfg[\"network_config\"]\n",
    "\n",
    "# initialize the decoder with last layer represent the mean and variance of the action distribution\n",
    "decoder = Decoder(\n",
    "    network_config[\"decoder_layer_sizes\"] + [network_config[\"action_size\"] * 2]\n",
    ")\n",
    "\n",
    "normalizer = running_statistics.normalize\n",
    "# load the normalizer parameters\n",
    "normalizer_param = ckpt[\"policy\"][0]\n",
    "\n",
    "# load the decoder parameters\n",
    "decoder_raw = ckpt[\"policy\"][1][\"params\"][\"decoder\"]\n",
    "decoder_param = {\"params\": decoder_raw}\n",
    "# initialize the action distribution\n",
    "action_distribution = distribution.NormalTanhDistribution(\n",
    "    event_size=network_config[\"action_size\"]\n",
    ")\n",
    "\n",
    "# prevent recompilation\n",
    "jit_env_reset = jax.jit(env.reset, static_argnames=(\"clip_idx\",))\n",
    "jit_env_step = jax.jit(env.step)\n",
    "jit_apply = jax.jit(decoder.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class DecoderTF(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layer_sizes,\n",
    "        activation=tf.nn.relu,\n",
    "        kernel_init=\"lecun_uniform\",\n",
    "        activate_final=False,\n",
    "        bias=True,\n",
    "        mean_std=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the Decoder, including the observation normalizer\n",
    "\n",
    "        Args:\n",
    "            layer_sizes (Sequence[int]): List of layer sizes for each Dense layer.\n",
    "            activation (callable): Activation function to apply.\n",
    "            kernel_init (str or callable): Kernel initializer for Dense layers.\n",
    "            activate_final (bool): Whether to apply activation (and layer norm) on the final layer.\n",
    "            bias (bool): Whether the Dense layers should use a bias term.\n",
    "            mean_std (tuple): Mean and standard deviation for obs normalization.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activation = activation\n",
    "        self.kernel_init = kernel_init\n",
    "        self.activate_final = activate_final\n",
    "        self.bias = bias\n",
    "        if mean_std is not None:\n",
    "            self.mean = tf.Variable(mean_std[0], trainable=False, dtype=tf.float32)\n",
    "            self.std = tf.Variable(mean_std[1], trainable=False, dtype=tf.float32)\n",
    "        else:\n",
    "            self.mean = None\n",
    "            self.std = None\n",
    "\n",
    "        # Build lists to store Dense layers and corresponding LayerNorm layers.\n",
    "        self.dense_layers = []\n",
    "        self.layer_norms = []\n",
    "\n",
    "        for i, size in enumerate(self.layer_sizes):\n",
    "            dense_layer = layers.Dense(\n",
    "                size,\n",
    "                kernel_initializer=self.kernel_init,\n",
    "                use_bias=self.bias,\n",
    "                name=f\"hidden_{i}\",\n",
    "            )\n",
    "            self.dense_layers.append(dense_layer)\n",
    "            # Apply activation and layer norm if it's not the final layer or if activate_final is True.\n",
    "            if i != len(self.layer_sizes) - 1 or self.activate_final:\n",
    "                self.layer_norms.append(\n",
    "                    layers.LayerNormalization(name=f\"LayerNorm_{i}\")\n",
    "                )\n",
    "            else:\n",
    "                self.layer_norms.append(None)\n",
    "\n",
    "    def call(self, inputs, get_activation=False):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            inputs (tf.Tensor): Input tensor.\n",
    "            get_activation (bool): If True, also return a dict with activations per layer.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor or Tuple[tf.Tensor, dict]: The output tensor, and optionally a dictionary\n",
    "            mapping layer names to their activations.\n",
    "        \"\"\"\n",
    "        if isinstance(inputs, list):\n",
    "            inputs = inputs[0]\n",
    "        activations = {}\n",
    "        if self.mean is not None and self.std is not None:\n",
    "            # Normalize the part of the input starting at column 60 (intention size TODO: config this).\n",
    "            normalized_part = (inputs[:, 60:] - self.mean) / self.std\n",
    "            # Concatenate the unchanged part with the normalized part along axis 1.\n",
    "            inputs = tf.concat([inputs[:, :60], normalized_part], axis=1)\n",
    "        x = inputs\n",
    "        for i, dense_layer in enumerate(self.dense_layers):\n",
    "            x = dense_layer(x)\n",
    "            # Apply activation (and layer norm) for all layers except the final one\n",
    "            # unless activate_final is True.\n",
    "            if i != len(self.layer_sizes) - 1 or self.activate_final:\n",
    "                x = self.activation(x)\n",
    "                if self.layer_norms[i] is not None:\n",
    "                    x = self.layer_norms[i](x)\n",
    "                if get_activation:\n",
    "                    activations[f\"layer_{i}\"] = x\n",
    "        if get_activation:\n",
    "            return x, activations\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_policy_network(\n",
    "    param_size,\n",
    "    hidden_layer_sizes=[512, 512, 512],\n",
    "    mean_std=None,\n",
    "):\n",
    "    policy_network = DecoderTF(\n",
    "        layer_sizes=list(hidden_layer_sizes) + [param_size],\n",
    "        mean_std=mean_std,\n",
    "    )\n",
    "    return policy_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_obs_size = cfg[\"network_config\"][\"reference_obs_size\"]\n",
    "mean_std = (normalizer_param.mean[ref_obs_size:], normalizer_param.std[ref_obs_size:])\n",
    "tf_policy_network = make_policy_network(\n",
    "    param_size=act_size * 2,\n",
    "    mean_std=mean_std,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = tf.zeros((1, 60 + 147))\n",
    "example_output = tf_policy_network(example_input)\n",
    "print(example_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_policy_network.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def transfer_weights(jax_params, tf_model):\n",
    "    \"\"\"\n",
    "    Transfer weights from a JAX parameter dictionary to the TensorFlow model.\n",
    "\n",
    "    Parameters:\n",
    "    - jax_params: dict\n",
    "      Nested dictionary with structure {block_name: {layer_name: {params}}}.\n",
    "      For example:\n",
    "      {\n",
    "        'CNN_0': {\n",
    "          'Conv_0': {'kernel': np.ndarray},\n",
    "          'Conv_1': {'kernel': np.ndarray},\n",
    "          'Conv_2': {'kernel': np.ndarray},\n",
    "        },\n",
    "        'MLP_0': {\n",
    "          'hidden_0': {'kernel': np.ndarray, 'bias': np.ndarray},\n",
    "          'hidden_1': {'kernel': np.ndarray, 'bias': np.ndarray},\n",
    "          'hidden_2': {'kernel': np.ndarray, 'bias': np.ndarray},\n",
    "        }\n",
    "      }\n",
    "\n",
    "    - tf_model: tf.keras.Model\n",
    "      An instance of the adapted VisionMLP model containing named submodules and layers.\n",
    "    \"\"\"\n",
    "    for layer_name, layer_params in jax_params.items():\n",
    "        try:\n",
    "            tf_layer = tf_model.get_layer(name=layer_name)\n",
    "        except ValueError:\n",
    "            print(f\"Layer {layer_name} not found in TensorFlow model.\")\n",
    "            continue\n",
    "        if isinstance(tf_layer, tf.keras.layers.Dense):\n",
    "            kernel = np.array(layer_params[\"kernel\"])\n",
    "            bias = np.array(layer_params[\"bias\"])\n",
    "            print(\n",
    "                f\"Transferring Dense layer {layer_name}, kernel shape {kernel.shape}, bias shape {bias.shape}\"\n",
    "            )\n",
    "            tf_layer.set_weights([kernel, bias])\n",
    "        elif isinstance(tf_layer, tf.keras.layers.LayerNormalization):\n",
    "            gamma = np.array(layer_params[\"scale\"])\n",
    "            beta = np.array(layer_params[\"bias\"])\n",
    "            print(\n",
    "                f\"Transferring LayerNorm layer {layer_name}, gamma shape {gamma.shape}, beta shape {beta.shape}\"\n",
    "            )\n",
    "            tf_layer.set_weights([gamma, beta])\n",
    "        else:\n",
    "            print(f\"Unhandled layer type in {layer_name}: {type(tf_layer)}\")\n",
    "\n",
    "    print(\"Weights transferred successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_weights(decoder_raw, tf_policy_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"decoder.onnx\"\n",
    "\n",
    "# Example inputs for the model\n",
    "test_input = [np.ones((1, 60 + 147), dtype=np.float32)]\n",
    "\n",
    "# Define the TensorFlow input signature\n",
    "spec = [tf.TensorSpec(shape=(1, 60 + 147), dtype=tf.float32, name=\"obs\")]\n",
    "\n",
    "tensorflow_pred = tf_policy_network(test_input)[0]\n",
    "# Build the model by calling it with example data\n",
    "print(f\"Tensorflow prediction: {tensorflow_pred}\")\n",
    "\n",
    "tf_policy_network.output_names = [\"continuous_actions\"]\n",
    "\n",
    "# opset 11 matches isaac lab.\n",
    "model_proto, _ = tf2onnx.convert.from_keras(\n",
    "    tf_policy_network, input_signature=spec, opset=11, output_path=output_path\n",
    ")\n",
    "\n",
    "# Run inference with ONNX Runtime\n",
    "output_names = [\"continuous_actions\"]\n",
    "providers = [\"CPUExecutionProvider\"]\n",
    "m = rt.InferenceSession(output_path, providers=providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_input = {\"obs\": np.ones((1, 147 + 60), dtype=np.float32)}\n",
    "# Prepare inputs for ONNX Runtime\n",
    "onnx_pred = m.run(output_names, onnx_input)[0][0]\n",
    "\n",
    "\n",
    "print(\"ONNX prediction shape:\", onnx_pred.shape)\n",
    "print(\"ONNX prediction:\", onnx_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = {\n",
    "    \"state\": jp.ones(obs_size[\"state\"]),\n",
    "    \"privileged_state\": jp.zeros(obs_size[\"privileged_state\"]),\n",
    "}\n",
    "jax_pred, _ = inference_fn(test_input, jax.random.PRNGKey(0))\n",
    "print(jax_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(onnx_pred.shape)\n",
    "print(tensorflow_pred.shape)\n",
    "print(jax_pred.shape)\n",
    "plt.plot(onnx_pred, label=\"onnx\")\n",
    "plt.plot(tensorflow_pred, label=\"tensorflow\")\n",
    "plt.plot(jax_pred, label=\"jax\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_cfg = locomotion.get_default_config(env_name)\n",
    "# env = locomotion.load(env_name, config=env_cfg)\n",
    "# jit_reset = jax.jit(env.reset)\n",
    "# jit_step = jax.jit(env.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the policy.\n",
    "\n",
    "# # env_cfg = locomotion.get_default_config(env_name)\n",
    "# # env_cfg.init_from_crouch = 0.0\n",
    "# # env = locomotion.load(env_name, config=env_cfg)\n",
    "# # env_cfg = manipulation.get_default_config(env_name)\n",
    "# # env = manipulation.load(env_name, config=env_cfg)\n",
    "# # jit_reset = jax.jit(env.reset)\n",
    "# # jit_step = jax.jit(env.step)\n",
    "\n",
    "# x = 0.8\n",
    "# y = 0.0\n",
    "# yaw = 0.3\n",
    "# command = jp.array([x, y, yaw])\n",
    "# # actions = []\n",
    "\n",
    "# states = [state := jit_reset(jax.random.PRNGKey(555))]\n",
    "# state.info[\"command\"] = command\n",
    "# for _ in range(env_cfg.episode_length):\n",
    "#   onnx_input = {'obs': np.array(state.obs[\"state\"].reshape(1, -1))}\n",
    "#   action = m.run(output_names, onnx_input)[0][0]\n",
    "#   state = jit_step(state, jp.array(action))\n",
    "#   state.info[\"command\"] = command\n",
    "#   states.append(state)\n",
    "#   # actions.append(state.info[\"motor_targets\"])\n",
    "#   # actions.append(action)\n",
    "#   if state.done:\n",
    "#     print(\"Unexpected termination.\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mediapy as media\n",
    "# fps = 1.0 / env.dt\n",
    "\n",
    "# frames = env.render(\n",
    "#     states,\n",
    "#     camera=\"track\",\n",
    "#     width=640*2,\n",
    "#     height=480*2,\n",
    "# )\n",
    "# media.show_video(frames, fps=fps, loop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track-mjx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
