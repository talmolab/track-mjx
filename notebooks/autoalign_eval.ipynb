{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import jax\n",
    "\n",
    "# Set Mujoco backend\n",
    "os.environ[\"MUJOCO_GL\"] = \"osmesa\"\n",
    "# Don't preallocate JAX memory\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_FLAGS\"] = (\n",
    "    \"--xla_gpu_enable_triton_softmax_fusion=true --xla_gpu_triton_gemm_any=True \"\n",
    ")\n",
    "from track_mjx.agent import checkpointing\n",
    "from track_mjx.environment import wrappers\n",
    "from track_mjx.environment.walker.rodent import Rodent\n",
    "from track_mjx.environment.task.reward import RewardConfig\n",
    "from track_mjx.environment.task.multi_clip_tracking import MultiClipTracking\n",
    "from track_mjx.io import load\n",
    "from brax import envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_env(cfg, reference_clip):\n",
    "    \"\"\"Set up the environment with the reference clip.\"\"\"\n",
    "    envs.register_environment(\"rodent_multi_clip\", MultiClipTracking)\n",
    "\n",
    "    env_args = cfg[\"env_config\"][\"env_args\"]\n",
    "    env_rewards = cfg[\"env_config\"][\"reward_weights\"]\n",
    "    walker_config = cfg[\"walker_config\"]\n",
    "    traj_config = cfg[\"reference_config\"]\n",
    "\n",
    "    # if eng_reward doesnt have energy_cost_weight, set it to 0.0\n",
    "    if \"energy_cost_weight\" not in env_rewards:\n",
    "        env_rewards[\"energy_cost_weight\"] = 0.0\n",
    "    walker = Rodent(**walker_config)\n",
    "    reward_config = RewardConfig(**env_rewards)\n",
    "\n",
    "    env = envs.get_environment(\n",
    "        env_name=\"rodent_multi_clip\",\n",
    "        reference_clip=reference_clip,\n",
    "        walker=walker,\n",
    "        reward_config=reward_config,\n",
    "        **env_args,\n",
    "        **traj_config,\n",
    "    )\n",
    "\n",
    "    rollout_env = wrappers.RenderRolloutWrapperMulticlipTracking(env)\n",
    "    align_vmap_env = wrappers.AutoAlignWrapperTracking(\n",
    "        wrappers.RenderRolloutVmapWrapper(rollout_env)\n",
    "    )\n",
    "\n",
    "    return align_vmap_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_eval_env(ckpt_path, eval_data_path, n_frames_per_clip=250):\n",
    "    ckpt = checkpointing.load_checkpoint_for_eval(ckpt_path)\n",
    "    cfg = ckpt[\"cfg\"]\n",
    "\n",
    "    # Load reference clip, get first 800 clips\n",
    "    reference_clip = load.make_multiclip_data(\n",
    "        eval_data_path, n_frames_per_clip=n_frames_per_clip\n",
    "    )\n",
    "    eval_reference_clip = jax.tree.map(lambda x: x[:400], reference_clip)\n",
    "    # Setup environment\n",
    "    env = setup_env(cfg, eval_reference_clip)\n",
    "\n",
    "    jit_align_reset = jax.jit(env.reset)\n",
    "    jit_align_step = jax.jit(env.step)\n",
    "\n",
    "    return env, jit_align_reset, jit_align_step, eval_reference_clip.position.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_checkpoint(\n",
    "    ckpt_path,\n",
    "    ckpt_step,\n",
    "    env,\n",
    "    reset_fn,\n",
    "    step_fn,\n",
    "    n_clips,\n",
    "    n_frames_per_clip=250,\n",
    "    num_envs=400,\n",
    "    max_batches=4,\n",
    "):\n",
    "    \"\"\"Evaluate a checkpoint on the eval dataset.\"\"\"\n",
    "    # Load checkpoint\n",
    "    ckpt = checkpointing.load_checkpoint_for_eval(ckpt_path, step=ckpt_step)\n",
    "    cfg = ckpt[\"cfg\"]\n",
    "\n",
    "    # Load inference function\n",
    "    inference_fn = checkpointing.load_inference_fn(\n",
    "        cfg, ckpt[\"policy\"], get_activation=False\n",
    "    )\n",
    "\n",
    "    # JIT-compile functions\n",
    "    jit_inference_fn = jax.jit(jax.vmap(inference_fn))\n",
    "\n",
    "    # Run rollouts and collect metrics\n",
    "    all_metrics = {\n",
    "        \"reward\": [],\n",
    "        \"done\": [],\n",
    "    }\n",
    "\n",
    "    batches = min(n_clips // num_envs, max_batches)\n",
    "    for i in range(batches):\n",
    "        print(f\"Processing clips {i * num_envs} to {i * num_envs + num_envs}\")\n",
    "\n",
    "        key_envs = jax.random.split(jax.random.PRNGKey(0), num_envs)\n",
    "        clip_idxs = jax.numpy.arange(0, num_envs) + i * num_envs\n",
    "\n",
    "        state = reset_fn(key_envs, clip_idx=clip_idxs)\n",
    "        rng_policy = jax.random.split(jax.random.PRNGKey(1), num_envs)\n",
    "\n",
    "        num_steps = int(n_frames_per_clip * env._steps_for_cur_frame) - 1\n",
    "        for _ in tqdm(range(num_steps)):\n",
    "            rng_policy = jax.vmap(jax.random.split)(rng_policy)[:, 1, :]\n",
    "            ctrl, _ = jit_inference_fn(state.obs, rng_policy)\n",
    "            state = step_fn(state, ctrl)\n",
    "            all_metrics[\"reward\"].append(state.reward)\n",
    "            all_metrics[\"done\"].append(state.metrics[\"done\"])\n",
    "\n",
    "    # Calculate metrics\n",
    "    reshaped_dones = np.array(all_metrics[\"done\"]).reshape(-1, order=\"F\")\n",
    "    reshaped_rewards = np.array(all_metrics[\"reward\"]).reshape(-1, order=\"F\")\n",
    "\n",
    "    avg_reward = float(reshaped_rewards.mean())\n",
    "\n",
    "    done_count = reshaped_dones.sum()\n",
    "    dones_per_hour = float(done_count * (3600 / (reshaped_dones.size / 100)))\n",
    "\n",
    "    return {\n",
    "        \"checkpoint_step\": ckpt_step,\n",
    "        \"avg_reward\": avg_reward,\n",
    "        \"dones_per_hour\": dones_per_hour,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate given a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"track-mjx/model_checkpoints/250220_125514\"\n",
    "test_data = \"transform_coltrane_2021_07_28_1.h5\"\n",
    "n_frames_per_clip = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env._steps_for_cur_frame: 2.0\n"
     ]
    }
   ],
   "source": [
    "env, reset_fn, step_fn, n_clips = make_eval_env(\n",
    "    ckpt_dir, test_data, n_frames_per_clip\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing clips 0 to 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [00:23<00:00, 21.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'checkpoint_step': 11,\n",
       " 'avg_reward': 4.156365394592285,\n",
       " 'dones_per_hour': 703.4067993164062}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = evaluate_checkpoint(\n",
    "    ckpt_dir,\n",
    "    11,\n",
    "    env,\n",
    "    reset_fn,\n",
    "    step_fn,\n",
    "    n_clips,\n",
    "    n_frames_per_clip=n_frames_per_clip,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
