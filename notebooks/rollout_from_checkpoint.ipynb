{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and render a rollout for existing checkpoint\n",
    "\n",
    "This notebook demonstrates how to load a training checkpoint, perform a rollout, and render the result. Full network activations are saved as an output of this rollout for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Handler \"orbax.checkpoint._src.handlers.array_checkpoint_handler.ArrayCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.array_checkpoint_handler.ArrayCheckpointHandler'>. Skipping registration.\n",
      "INFO:absl:Handler \"orbax.checkpoint._src.handlers.proto_checkpoint_handler.ProtoCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.proto_checkpoint_handler.ProtoCheckpointHandler'>. Skipping registration.\n",
      "INFO:absl:Handler \"orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler'>. Skipping registration.\n",
      "INFO:absl:Handler \"orbax.checkpoint._src.handlers.base_pytree_checkpoint_handler.BasePyTreeCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.base_pytree_checkpoint_handler.BasePyTreeCheckpointHandler'>. Skipping registration.\n",
      "INFO:absl:Handler \"orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler'>. Skipping registration.\n",
      "INFO:absl:Handler \"orbax.checkpoint._src.handlers.standard_checkpoint_handler.StandardCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.standard_checkpoint_handler.StandardCheckpointHandler'>. Skipping registration.\n",
      "INFO:absl:Handler \"orbax.checkpoint._src.handlers.random_key_checkpoint_handler.JaxRandomKeyCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.random_key_checkpoint_handler.JaxRandomKeyCheckpointHandler'>. Skipping registration.\n",
      "INFO:absl:Handler \"orbax.checkpoint._src.handlers.random_key_checkpoint_handler.NumpyRandomKeyCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.random_key_checkpoint_handler.NumpyRandomKeyCheckpointHandler'>. Skipping registration.\n",
      "INFO:absl:Handler \"orbax.checkpoint.test_utils.ErrorCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint.test_utils.ErrorCheckpointHandler'>. Skipping registration.\n",
      "INFO:absl:MUJOCO_GL=osmesa, attempting to import specified OpenGL backend.\n",
      "INFO:absl:MuJoCo library version is: 3.3.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "# Send logging outputs to stdout (comment this out if preferred)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Change this to egl or glfw if available\n",
    "os.environ[\"MUJOCO_GL\"] = \"osmesa\"\n",
    "\n",
    "from track_mjx.agent import checkpointing\n",
    "from track_mjx.analysis.rollout import (\n",
    "    create_rollout_generator,\n",
    "    create_environment,\n",
    ")\n",
    "from track_mjx.analysis.render import render_from_saved_rollout, display_video\n",
    "from track_mjx.analysis.utils import save_to_h5py, load_from_h5py\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:[thread=MainThread] Failed to get flag value for EXPERIMENTAL_ORBAX_USE_DISTRIBUTED_PROCESS_ID.\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "INFO:absl:[process=0][thread=MainThread] CheckpointManager init: checkpointers=None, item_names=None, item_handlers=None, handler_registry=None\n",
      "INFO:absl:Initialized registry DefaultCheckpointHandlerRegistry({('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x7efc395eea90>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x7efc395eea90>}).\n",
      "INFO:absl:orbax-checkpoint version: 0.11.5\n",
      "INFO:absl:[process=0][thread=MainThread] Using barrier_sync_fn: <function get_barrier_sync_fn.<locals>.<lambda> at 0x7efc381c3420> timeout: 600 secs and primary_host=0 for async checkpoint writes\n",
      "INFO:absl:Read Metadata={'item_handlers': {'config': 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler', 'policy': 'orbax.checkpoint._src.handlers.standard_checkpoint_handler.StandardCheckpointHandler', 'train_state': 'orbax.checkpoint._src.handlers.standard_checkpoint_handler.StandardCheckpointHandler'}, 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1742066498825105548, 'commit_timestamp_nsecs': 1742066499490252271, 'custom': {}} from /home/tim.kim/track-mjx/model_checkpoints/250315_113155/PPONetwork_2/_CHECKPOINT_METADATA\n",
      "INFO:absl:Found 5 checkpoint steps in /home/tim.kim/track-mjx/model_checkpoints/250315_113155\n",
      "INFO:absl:[process=0][thread=MainThread] CheckpointManager created,  primary_host=0, CheckpointManagerOptions=CheckpointManagerOptions(save_interval_steps=1, max_to_keep=None, keep_time_interval=None, keep_period=None, should_keep_fn=None, best_fn=None, best_mode='max', keep_checkpoints_without_metrics=True, step_prefix='PPONetwork', step_format_fixed_length=None, step_name_format=None, create=False, cleanup_tmp_directories=False, save_on_steps=frozenset(), single_host_load_and_broadcast=False, todelete_subdir=None, enable_background_delete=False, read_only=False, enable_async_checkpointing=True, async_options=None, multiprocessing_options=MultiprocessingOptions(primary_host=0, active_processes=None, barrier_sync_key_prefix=None), should_save_fn=None, file_options=FileOptions(path_permission_mode=None), save_root_metadata=True, temporary_path_class=None, save_decision_policy=None), root_directory=/home/tim.kim/track-mjx/model_checkpoints/250315_113155: <orbax.checkpoint.checkpoint_manager.CheckpointManager object at 0x7efc3b458c10>\n",
      "INFO:root:Loading checkpoint from /home/tim.kim/track-mjx/model_checkpoints/250315_113155/ at step 4\n",
      "INFO:absl:[process=0][thread=MainThread] CheckpointManager init: checkpointers=None, item_names=None, item_handlers=None, handler_registry=None\n",
      "INFO:absl:Initialized registry DefaultCheckpointHandlerRegistry({('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x7efc381da310>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x7efc381da310>}).\n",
      "INFO:absl:[process=0][thread=MainThread] Using barrier_sync_fn: <function get_barrier_sync_fn.<locals>.<lambda> at 0x7efc381c3920> timeout: 600 secs and primary_host=0 for async checkpoint writes\n",
      "INFO:absl:Found 5 checkpoint steps in /home/tim.kim/track-mjx/model_checkpoints/250315_113155\n",
      "INFO:absl:[process=0][thread=MainThread] CheckpointManager created,  primary_host=0, CheckpointManagerOptions=CheckpointManagerOptions(save_interval_steps=1, max_to_keep=None, keep_time_interval=None, keep_period=None, should_keep_fn=None, best_fn=None, best_mode='max', keep_checkpoints_without_metrics=True, step_prefix='PPONetwork', step_format_fixed_length=None, step_name_format=None, create=False, cleanup_tmp_directories=False, save_on_steps=frozenset(), single_host_load_and_broadcast=False, todelete_subdir=None, enable_background_delete=False, read_only=False, enable_async_checkpointing=True, async_options=None, multiprocessing_options=MultiprocessingOptions(primary_host=0, active_processes=None, barrier_sync_key_prefix=None), should_save_fn=None, file_options=FileOptions(path_permission_mode=None), save_root_metadata=True, temporary_path_class=None, save_decision_policy=None), root_directory=/home/tim.kim/track-mjx/model_checkpoints/250315_113155: <orbax.checkpoint.checkpoint_manager.CheckpointManager object at 0x7efc391d4490>\n",
      "INFO:root:Loading config from /home/tim.kim/track-mjx/model_checkpoints/250315_113155/ at step 4\n",
      "INFO:absl:Restoring checkpoint from /home/tim.kim/track-mjx/model_checkpoints/250315_113155/PPONetwork_4.\n",
      "INFO:absl:No entry found in handler registry for item: config and args with type: <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>. Falling back to global handler registry.\n",
      "INFO:absl:Deferred registration for item: \"config\". Adding handler `<orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x7efc38edccd0>` for item \"config\" and save args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>` to `_handler_registry`.\n",
      "INFO:absl:Finished restoring checkpoint in 0.00 seconds from /home/tim.kim/track-mjx/model_checkpoints/250315_113155/PPONetwork_4.\n",
      "INFO:absl:{'step': 4, 'event_type': 'restore', 'directory': '/home/tim.kim/track-mjx/model_checkpoints/250315_113155', 'checkpointer_start_time': 1745097271.2173505, 'checkpointer_duration_secs': 0.005598783493041992, 'checkpoint_manager_start_time': 1745097271.217254, 'checkpoint_manager_duration_secs': 0.005697011947631836}\n",
      "INFO:absl:[process=0][thread=MainThread][wait_until_finished] Initiating wait for Save Finalize thread.\n",
      "INFO:absl:[process=0][thread=MainThread][wait_until_finished] No Save Finalize thread to wait for. Returning.\n",
      "INFO:absl:Closing _NonBlockingMetadataStore(enable_write=True, _write_lock=<locked _thread.RLock object owner=139629200540096 count=1 at 0x7efc381dab40>, _store_impl=<orbax.checkpoint._src.metadata.checkpoint._MetadataStoreImpl object at 0x7efc381dbc10>, _single_thread_executor=<concurrent.futures.thread.ThreadPoolExecutor object at 0x7efc381d9e50>, _write_futures=[])\n",
      "INFO:absl:Closing _NonBlockingMetadataStore(enable_write=True, _write_lock=<locked _thread.RLock object owner=139629200540096 count=1 at 0x7efc381dab40>, _store_impl=<orbax.checkpoint._src.metadata.checkpoint._MetadataStoreImpl object at 0x7efc381dbc10>, _single_thread_executor=<concurrent.futures.thread.ThreadPoolExecutor object at 0x7efc381d9e50>, _write_futures=[])\n",
      "INFO:absl:Closing _NonBlockingMetadataStore(enable_write=True, _write_lock=<locked _thread.RLock object owner=139629200540096 count=1 at 0x7efc381dab40>, _store_impl=<orbax.checkpoint._src.metadata.checkpoint._MetadataStoreImpl object at 0x7efc381dbc10>, _single_thread_executor=<concurrent.futures.thread.ThreadPoolExecutor object at 0x7efc381d9e50>, _write_futures=[])\n",
      "INFO:absl:Restoring checkpoint from /home/tim.kim/track-mjx/model_checkpoints/250315_113155/PPONetwork_4.\n",
      "INFO:absl:No entry found in handler registry for item: policy and args with type: <class 'orbax.checkpoint._src.handlers.standard_checkpoint_handler.StandardRestoreArgs'>. Falling back to global handler registry.\n",
      "INFO:absl:Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None\n",
      "INFO:absl:Deferred registration for item: \"policy\". Adding handler `<orbax.checkpoint._src.handlers.standard_checkpoint_handler.StandardCheckpointHandler object at 0x7efc24138b90>` for item \"policy\" and save args `<class 'orbax.checkpoint._src.handlers.standard_checkpoint_handler.StandardSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.standard_checkpoint_handler.StandardRestoreArgs'>` to `_handler_registry`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Requested shape: (470, 512) is not compatible with the stored shape: (617, 512). Truncating/padding is disabled by setting of `strict=True`. When using standard Orbax APIs, this behavior can be modified by specifying `strict=False` in `ArrayRestoreArgs` for any array in which padding/truncation is desired.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m ckpt_path = \u001b[33m\"\u001b[39m\u001b[33m/home/tim.kim/track-mjx/model_checkpoints/250315_113155/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load config from checkpoint \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ckpt = \u001b[43mcheckpointing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_checkpoint_for_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m cfg = ckpt[\u001b[33m\"\u001b[39m\u001b[33mcfg\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# make some changes to the config\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# replace with absolute path to your data\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# -- your notebook may not have access to the same relative path\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/track-mjx/track_mjx/agent/checkpointing.py:87\u001b[39m, in \u001b[36mload_checkpoint_for_eval\u001b[39m\u001b[34m(checkpoint_path, step_prefix, step)\u001b[39m\n\u001b[32m     84\u001b[39m abstract_policy = make_abstract_policy(cfg)\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# Then load the policy given the pytree structure\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m policy = \u001b[43mckpt_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mComposite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStandardRestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabstract_policy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mpolicy\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mcfg\u001b[39m\u001b[33m\"\u001b[39m: cfg, \u001b[33m\"\u001b[39m\u001b[33mpolicy\u001b[39m\u001b[33m\"\u001b[39m: policy}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py:1419\u001b[39m, in \u001b[36mCheckpointManager.restore\u001b[39m\u001b[34m(self, step, items, restore_kwargs, directory, args)\u001b[39m\n\u001b[32m   1417\u001b[39m restore_directory = \u001b[38;5;28mself\u001b[39m._get_read_step_directory(step, directory)\n\u001b[32m   1418\u001b[39m step_stats.checkpointer_start_time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1419\u001b[39m restored = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_checkpointer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestore_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1420\u001b[39m step_stats.checkpointer_duration_secs = (\n\u001b[32m   1421\u001b[39m     time.time() - step_stats.checkpointer_start_time\n\u001b[32m   1422\u001b[39m )\n\u001b[32m   1424\u001b[39m step_stats.checkpoint_manager_duration_secs = (\n\u001b[32m   1425\u001b[39m     time.time() - step_stats.checkpoint_manager_start_time\n\u001b[32m   1426\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/checkpointers/async_checkpointer.py:504\u001b[39m, in \u001b[36mAsyncCheckpointer.restore\u001b[39m\u001b[34m(self, directory, *args, **kwargs)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"See superclass documentation.\"\"\"\u001b[39;00m\n\u001b[32m    503\u001b[39m \u001b[38;5;28mself\u001b[39m.wait_until_finished()\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/checkpointers/checkpointer.py:279\u001b[39m, in \u001b[36mCheckpointer.restore\u001b[39m\u001b[34m(self, directory, *args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m logging.info(\u001b[33m'\u001b[39m\u001b[33mRestoring checkpoint from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m, directory)\n\u001b[32m    278\u001b[39m ckpt_args = construct_checkpoint_args(\u001b[38;5;28mself\u001b[39m._handler, \u001b[38;5;28;01mFalse\u001b[39;00m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m restored = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_restore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m multihost.sync_global_processes(\n\u001b[32m    281\u001b[39m     multihost.unique_barrier_key(\n\u001b[32m    282\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCheckpointer:restore\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    285\u001b[39m     processes=\u001b[38;5;28mself\u001b[39m._active_processes,\n\u001b[32m    286\u001b[39m )\n\u001b[32m    287\u001b[39m restore_duration_secs = time.time() - restore_start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/checkpointers/checkpointer.py:298\u001b[39m, in \u001b[36mCheckpointer._restore\u001b[39m\u001b[34m(self, directory, args)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_restore\u001b[39m(\n\u001b[32m    296\u001b[39m     \u001b[38;5;28mself\u001b[39m, directory: epath.PathLike, args: checkpoint_args.CheckpointArgs\n\u001b[32m    297\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/handlers/composite_checkpoint_handler.py:839\u001b[39m, in \u001b[36mCompositeCheckpointHandler.restore\u001b[39m\u001b[34m(self, directory, args)\u001b[39m\n\u001b[32m    834\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    835\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mItem \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m was not found in the checkpoint. Available\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    836\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m items: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexisting_items\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    837\u001b[39m     )\n\u001b[32m    838\u001b[39m   handler = \u001b[38;5;28mself\u001b[39m._get_or_set_handler(item_name, arg)\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m   restored[item_name] = \u001b[43mhandler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_item_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43marg\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CompositeResults(**restored)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/handlers/standard_checkpoint_handler.py:244\u001b[39m, in \u001b[36mStandardCheckpointHandler.restore\u001b[39m\u001b[34m(self, directory, item, args)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args.strict:\n\u001b[32m    243\u001b[39m   restore_args = jax.tree.map(_replace_strict, restore_args)\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_impl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpytree_checkpoint_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPyTreeRestoreArgs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrestore_args\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/handlers/pytree_checkpoint_handler.py:796\u001b[39m, in \u001b[36mPyTreeCheckpointHandler.restore\u001b[39m\u001b[34m(self, directory, item, restore_args, transforms, transforms_default_to_original, legacy_transform_fn, args)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    787\u001b[39m     (directory / PYTREE_METADATA_FILE).exists()\n\u001b[32m    788\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m can_ignore_aggregate_file\n\u001b[32m    789\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m transforms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m legacy_transform_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    791\u001b[39m ):\n\u001b[32m    792\u001b[39m   args = BasePyTreeRestoreArgs(\n\u001b[32m    793\u001b[39m       item,\n\u001b[32m    794\u001b[39m       restore_args=restore_args,\n\u001b[32m    795\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handler_impl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    798\u001b[39m logging.vlog(\u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdirectory=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, restore_args=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m, directory, restore_args)\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m directory.exists():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/handlers/base_pytree_checkpoint_handler.py:733\u001b[39m, in \u001b[36mBasePyTreeCheckpointHandler.restore\u001b[39m\u001b[34m(self, directory, args)\u001b[39m\n\u001b[32m    725\u001b[39m param_infos = \u001b[38;5;28mself\u001b[39m._get_param_infos(\n\u001b[32m    726\u001b[39m     item=value_metadata_tree,\n\u001b[32m    727\u001b[39m     directory=directory,\n\u001b[32m   (...)\u001b[39m\u001b[32m    730\u001b[39m     raise_array_data_missing_error=raise_array_data_missing_error,\n\u001b[32m    731\u001b[39m )\n\u001b[32m    732\u001b[39m \u001b[38;5;66;03m# Begin restore.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m tree_memory_size, restored_item = \u001b[43masyncio_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_deserialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m        \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_metadata_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_args\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging.vlog_is_on(\u001b[32m1\u001b[39m):\n\u001b[32m    740\u001b[39m   logging.vlog(\u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mparam_infos: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m, param_infos)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/asyncio_utils.py:50\u001b[39m, in \u001b[36mrun_sync\u001b[39m\u001b[34m(coro, enable_nest_asyncio)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[32m     49\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/asyncio/tasks.py:279\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m         result = coro.throw(exc)\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    282\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/handlers/base_pytree_checkpoint_handler.py:581\u001b[39m, in \u001b[36mBasePyTreeCheckpointHandler._maybe_deserialize\u001b[39m\u001b[34m(self, item, metadata, param_infos, restore_args)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m request \u001b[38;5;129;01min\u001b[39;00m batch_requests:\n\u001b[32m    578\u001b[39m   deserialized_batches_ops.append(\n\u001b[32m    579\u001b[39m       request.handler.deserialize(request.infos, request.args)\n\u001b[32m    580\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m deserialized_batches += \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*deserialized_batches_ops)\n\u001b[32m    583\u001b[39m tree_memory_size = \u001b[32m0\u001b[39m\n\u001b[32m    584\u001b[39m flat_restored = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/asyncio/tasks.py:279\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m         result = coro.throw(exc)\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    282\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/serialization/type_handlers.py:1232\u001b[39m, in \u001b[36mArrayHandler.deserialize\u001b[39m\u001b[34m(self, infos, args)\u001b[39m\n\u001b[32m   1219\u001b[39m     logging.vlog(\u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msharding = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m, sharding)\n\u001b[32m   1220\u001b[39m   deserialize_ops += [\n\u001b[32m   1221\u001b[39m       serialization.async_deserialize(\n\u001b[32m   1222\u001b[39m           sharding,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1230\u001b[39m       )\n\u001b[32m   1231\u001b[39m   ]\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m ret = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*deserialize_ops)\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging.vlog_is_on(\u001b[32m1\u001b[39m):\n\u001b[32m   1235\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m ret:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/asyncio/tasks.py:279\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m         result = coro.throw(exc)\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    282\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/serialization/serialization.py:543\u001b[39m, in \u001b[36masync_deserialize\u001b[39m\u001b[34m(user_sharding, tensorstore_spec, global_shape, dtype, byte_limiter, context, assume_metadata, strict)\u001b[39m\n\u001b[32m    541\u001b[39m global_shape = \u001b[38;5;28mtuple\u001b[39m(t.shape \u001b[38;5;28;01mif\u001b[39;00m global_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m global_shape)\n\u001b[32m    542\u001b[39m new_shard_shape = sharding.shard_shape(global_shape)\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m read_and_create_array(\n\u001b[32m    544\u001b[39m     t,\n\u001b[32m    545\u001b[39m     global_shape=global_shape,\n\u001b[32m    546\u001b[39m     new_shard_shape=new_shard_shape,\n\u001b[32m    547\u001b[39m     sharding=sharding,\n\u001b[32m    548\u001b[39m     dtype=dtype,\n\u001b[32m    549\u001b[39m     byte_limiter=byte_limiter,\n\u001b[32m    550\u001b[39m     strict=strict,\n\u001b[32m    551\u001b[39m     dll=dll,\n\u001b[32m    552\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/serialization/serialization.py:502\u001b[39m, in \u001b[36mread_and_create_array\u001b[39m\u001b[34m(t, global_shape, new_shard_shape, sharding, dtype, byte_limiter, strict, dll)\u001b[39m\n\u001b[32m    484\u001b[39m     local_indices_devices_map[\n\u001b[32m    485\u001b[39m         np_utils.to_hashable_index(idx, shape=global_shape)\n\u001b[32m    486\u001b[39m     ].append(d)\n\u001b[32m    488\u001b[39m read_array_coros = [\n\u001b[32m    489\u001b[39m     _read_array_index_and_device_put(\n\u001b[32m    490\u001b[39m         devices,\n\u001b[32m   (...)\u001b[39m\u001b[32m    500\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, devices \u001b[38;5;129;01min\u001b[39;00m local_indices_devices_map.items()\n\u001b[32m    501\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m dbs = \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*read_array_coros), [])\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m jax.make_array_from_single_device_arrays(global_shape, sharding, dbs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/track_mjx/lib/python3.11/site-packages/orbax/checkpoint/_src/serialization/serialization.py:419\u001b[39m, in \u001b[36m_read_array_index_and_device_put\u001b[39m\u001b[34m(devices, index, t, global_shape, new_shard_shape, dtype, byte_limiter, strict, dll)\u001b[39m\n\u001b[32m    417\u001b[39m     restricted_domain = domain\n\u001b[32m    418\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    420\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRequested shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglobal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not compatible with the stored\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    421\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Truncating/padding is disabled by setting of\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    422\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m `strict=True`. When using standard Orbax APIs, this behavior can\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    423\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m be modified by specifying `strict=False` in `ArrayRestoreArgs` for\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    424\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m any array in which padding/truncation is desired.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    425\u001b[39m     )\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    427\u001b[39m   requested_domain = ts.IndexTransform(input_shape=global_shape)[index].domain\n",
      "\u001b[31mValueError\u001b[39m: Requested shape: (470, 512) is not compatible with the stored shape: (617, 512). Truncating/padding is disabled by setting of `strict=True`. When using standard Orbax APIs, this behavior can be modified by specifying `strict=False` in `ArrayRestoreArgs` for any array in which padding/truncation is desired."
     ]
    }
   ],
   "source": [
    "# replace with your checkpoint path\n",
    "ckpt_path = \"/home/tim.kim/track-mjx/model_checkpoints/250315_113155/\"\n",
    "# Load config from checkpoint \n",
    "ckpt = checkpointing.load_checkpoint_for_eval(ckpt_path)\n",
    "\n",
    "cfg = ckpt[\"cfg\"]\n",
    "\n",
    "# make some changes to the config\n",
    "# replace with absolute path to your data\n",
    "# -- your notebook may not have access to the same relative path\n",
    "cfg.data_path = \"/allen/aind/scratch/tim.kim/track-mjx/data/transform_snips.h5\"\n",
    "cfg.train_setup.checkpoint_to_restore = ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore policy and make rollout functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_environment(cfg)\n",
    "inference_fn = checkpointing.load_inference_fn(cfg, ckpt[\"policy\"])\n",
    "generate_rollout = create_rollout_generator(cfg, env, inference_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate rollouts from the checkpoint\n",
    "\n",
    "After we load the checkpoint, we can do inference on the rollout!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate a rollout imitating single clip, specified by the clip index. The first time you call the function there will be ~1-3min of compilation time, after which it will take only a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_rollout = generate_rollout(clip_idx=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Generating Rollouts\n",
    "\n",
    "Alternatively, you can use `jax.vmap` to parallelize the rollout function. This is useful for performing a rollout over an entire dataset for eval/analysis purposes. We pass in a 1D array of clip indexes (`clip_idxs`) as input. \n",
    "\n",
    "The first run for this will also have a few minutes of compilation time.\n",
    "\n",
    "**Note:** `vmap` compiles based on the input shape. This means that if you use the same length for `clip_idxs`, JAX will reuse the compiled function for acceleration. However, if the input length changes, JAX will **recompile the entire function**, incurring additional overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate rollout for 5 clips simultaneously\n",
    "jit_vmap_generate_rollout = jax.jit(jax.vmap(generate_rollout))\n",
    "clip_idxs = jp.arange(0, 5)\n",
    "jit_vmap_out = jit_vmap_generate_rollout(clip_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running it with a different clip_idxs length will cause reocmpilation\n",
    "clip_idxs = jp.arange(15, 30)\n",
    "jit_vmap_out2 = jit_vmap_generate_rollout(clip_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(ckpt_path) / \"rollout.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_h5py(save_path.resolve(), single_rollout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render Rollout Videos from the Saved Rollouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the rollout file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = load_from_h5py(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render rollout\n",
    "\n",
    "Note: Currently only works for non-batched rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, realtime_framerate = render_from_saved_rollout(cfg, rollout)\n",
    "display_video(frames, framerate=realtime_framerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track_mjx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
