{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess STAC-MJX output to TRACK-MJX input\n",
    "\n",
    "Hacky hard code for now for test run. This will be in a separate module under `track_mjx.io.preprocess`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jax\n",
    "from jax import jit, vmap\n",
    "\n",
    "import mujoco \n",
    "\n",
    "from mujoco import mjx\n",
    "\n",
    "from dm_control import mjcf\n",
    "from dm_control.locomotion.walkers import rescale\n",
    "\n",
    "import pickle\n",
    "\n",
    "from track_mjx.io.preprocess.mjx_preprocess import process_clip\n",
    "\n",
    "# setup environment and stac data for preprocessing\n",
    "scale_factor = 0.9\n",
    "stac_path = \"../data/transform_snips_new.p\"\n",
    "\n",
    "with open(stac_path, \"rb\") as file:\n",
    "        d = pickle.load(file)        \n",
    "        data_qpos = d[\"qpos\"]\n",
    "        \n",
    "# Load rodent mjcf and rescale, then get the mj_model from that.\n",
    "# TODO: make this all work in mjx? james cotton did rescaling with mjx model:\n",
    "# https://github.com/peabody124/BodyModels/blob/f6ef1be5c5d4b7e51028adfc51125e510c13bcc2/body_models/biomechanics_mjx/forward_kinematics.py#L92\n",
    "root = mjcf.from_path(\"../track_mjx/walker/assets/rodent.xml\")\n",
    "rescale.rescale_subtree(\n",
    "    root,\n",
    "    scale_factor,\n",
    "    scale_factor,\n",
    ")\n",
    "mj_model = mjcf.Physics.from_mjcf_model(root).model.ptr\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "\n",
    "    # Place into GPU\n",
    "mjx_model = mjx.put_model(mj_model)\n",
    "mjx_data = mjx.put_data(mj_model, mj_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_length = 250\n",
    "# Split clip like this if you want to run just once\n",
    "start_step = 0\n",
    "first_clip_qpos = data_qpos[start_step : start_step + clip_length]\n",
    "\n",
    "# jit the process_clip function\n",
    "jit_process_clip = jax.jit(process_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape qposes to have the batch dimension and vmap the jitted function\n",
    "all_clips_qpos = data_qpos.reshape((-1, clip_length, mjx_model.nq))\n",
    "vmap_jit_process_clip = vmap(jit_process_clip, in_axes=(0, None, None))\n",
    "all_clips_qpos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clips = vmap_jit_process_clip(all_clips_qpos, mjx_model, mjx_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/ReferenceClip.p\", \"wb\") as f:\n",
    "    pickle.dump(all_clips, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_clips = vmap_jit_process_clip(all_clips_qpos[:2], mjx_model, mjx_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_clips.position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/twoClips.p\", \"wb\") as f:\n",
    "    pickle.dump(two_clips, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clips.position.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving and loading (wip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_reference_clip_to_h5(filename, reference_clip):\n",
    "    \"\"\"\n",
    "    Save the contents of a ReferenceClip object to an .h5 file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the .h5 file to save to.\n",
    "        reference_clip (ReferenceClip): The ReferenceClip object to save.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'w') as hf:\n",
    "        for attr, value in reference_clip.__dict__.items():\n",
    "            if value is not None:\n",
    "                # Create a group for each batch\n",
    "                for batch_idx in range(value.shape[0]):\n",
    "                    #TODO: instead of batch_x, save as the name given by d[\"snips_order\"]\n",
    "                    # and save the order as its own thing at the top level\n",
    "                    group_name = f\"{attr}/batch_{batch_idx}\"\n",
    "                    hf.create_dataset(group_name, data=value[batch_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"ReferenceClip.p\"\n",
    "save_reference_clip_to_h5(filename, all_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from track_mjx.io.preprocess.mjx_preprocess import ReferenceClip\n",
    "from jax import numpy as jp\n",
    "def load_reference_clip_from_h5(filename):\n",
    "    \"\"\"\n",
    "    Load the contents of an .h5 file into a ReferenceClip object.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the .h5 file to load from.\n",
    "\n",
    "    Returns:\n",
    "        ReferenceClip: The reconstructed ReferenceClip object.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as hf:\n",
    "        clip = ReferenceClip()\n",
    "        for attr in clip.__dict__.keys():\n",
    "            batch_data = []\n",
    "            batch_idx = 0\n",
    "            while f\"{attr}/batch_{batch_idx}\" in hf:\n",
    "                batch_data.append(hf[f\"{attr}/batch_{batch_idx}\"][:])\n",
    "                batch_idx += 1\n",
    "            if batch_data:\n",
    "                setattr(clip, attr, jp.stack(batch_data))\n",
    "        return clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import fields\n",
    "\n",
    "for field in fields(all_clips):\n",
    "    print(field.name, getattr(all_clips, field.name).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_datasets(file_path):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        def print_datasets(name, obj):\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                print(f\"Dataset: {name}\")\n",
    "                print(f\"  Shape: {obj.shape}\")\n",
    "                print(f\"  Dtype: {obj.dtype}\")\n",
    "                print(f\"  Attributes: {dict(obj.attrs)}\")\n",
    "                print()\n",
    "\n",
    "        f.visititems(print_datasets)\n",
    "        \n",
    "view_datasets(f\"../data/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_all_clips = load_reference_clip_from_h5(f\"../data/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track_mjx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
